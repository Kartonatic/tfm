
\section{Validación\label{validacion}}

En este apartado vamos a analizar como se ha comportado la arquitectura propuesta sobre el hardware que hemos usado. Evidentemente, los resultados de tiempo de ejecución no corresponden con los de un cluster real pero, por motivos de disponibilidad, no se ha podido realizar el estudio sobre uno de estos.\par

La arquitectura propuesta nos a aportado una flexibilidad que, con una arquitectura tradicional no tendríamos. En el caso de una arquitectura Lambda tenemos dos vías para las cuales realizar procesamientos. Por un lado tenemos la batch layer para los procedimientos más costosos y que requieren obtener datos de histórico y por otro la Speed layer que nos permitirá obtener los procesamientos de tiempo real que nos sean necesarios. También, dado que la funcionalidad no está certificada en una sola aplicación sino que, distinguimos varias partes, hace que reemplazar cualquier herramienta sea una tarea más sencilla. Dado esto y, principalmente por poder separar los procesamientos en tiempo real y de histórico, la arquitectura Lambda es más que recomendable en sistemas de IoT que requieren gran cantidad de procesamientos y, más aún, en las aplicaciones dirigidas al transporte y gestión de flotas.\par

En cuanto a las herramientas utilizadas, comenzaremos analizando el uso de Docker sobre esta arquitectura. Docker, nos a aportado la capacidad de mover las diferentes herramientas de un sitio a otro sin ningun problema gracias a la encapsulación, lo que hará que sea más fácil poder probarlo en un cluster en un futuro. Por otro lado, aunque la curva de aprendizaje es dura al principio, luego se hace realmente fácil de manejar, aportando las ventajas vistas en el apartado \ref{Docker}.\par

En cuanto a Apache Kafka, hemos encontrado un rendimiento más que notable, siendo capaces de leer con varios procesos sobre un mismo Topic cuando hemos realizado las diferentes pruebas. Además de esto, el hecho de que sea tan fácil de configurar lo hace una herramienta muy recomendable. Una de las propiedades que más llama la atención de Kafka y es lo que lo hace tan potente, es que podemos almacenar los mensajes durante un tiempo, lo que hace que podamos leer gran cantidad de tramas en el momentos determinados. Esto hace que en aplicaciones de gestión de flotas sea muy recomendable ya que podemos buscar tramas erróneas en diferentes procesos de análisis que se pueden ir ejecutando por otra parte.\par

Por la parte de Hadoop, encontramos que el tratamiento de datos es complicado sin herramientas como Hive. Sin embargo, también hemos encontrado la facilidad de integrarlo con diferentes herramientas. Por otro lado, también vemos que el sistema de ficheros HDFS nos da la ventaja de dejar de tener que usar RAIDs en nuestros servidores y poder acceder a los datos de una forma rápida.\par

Por la parte de Spark, encontramos que las operaciones para obtener los usuarios y comprobar si está cerca de un punto negro, se realizan muy eficientemente y se pueden tratar las tramas rápidamente. Con las pruebas realizadas hemos podido tratar más de 3000 tramas por debajo de los 10 segundos del microbaching. También se ha observado que la primera vez tarda más debido a que tiene que cargar los datos de los usuarios y las primeras iteraciones van desacompasadas. También encontramos que, al mantener el índice de Kafka, si lo paramos y lo volvemos a ejecutar, procesa todas las tramas desde que se paró hasta que vuelve a ponerse en ejecución. Aún así, el proceso es capaz de recuperarse en unos minutos realizando el procesamiento streaming a su hora. Por otro lado, hemos comprobado que el rendimiento añadiendo las consultas a la base de datos de OSM, penaliza mucho el rendimiento. Realizando dichas consultas, el procesamiento no es capaz de procesar las 3000 tramas en los 10 segundos de tiempo que se usan, llegando a tardar más de 40 segundos para procesarlas. Aunque el proceso es capaz de procesar las tramas, no es capaz de acompasarse debido al acceso a datos. Aunque existe la posibilidad de integrar MongoDB con Spark, descartamos dicha opción ya que carga toda la colección para hacer uso de ella, por lo que no sería eficiente en memoria en el caso de la base de datos de OSM. Por otro lado, encontramos que es realmente sencillo de usar, ya que con un solo script de Python no hemos tenido que manejar la concurrencia entre los diferentes servidores y, además, nos ofrece gran cantidad de operaciones que podríamos encontrar en una base de datos relacional tradicional. \par

En cuanto a MongoDB encontramos que es una herramienta muy potente a la hora de manejar gran cantidad de datos. Encontramos una gran flexibilidad a la hora de introducir datos que no encontramos por parte de las bases de datos relacionales, que al manejar gran cantidad de filas sin indexar, se hacen mucho más lentas. Además, es muy fácil realizar APIs sobre esta ya que el mismo motor devuelve objetos JSON muy usados en el mundo web. Por tanto, calificamos esta herramienta como válida para diferentes propósitos, pero muy especialmente en el nuestro, por la flexibilidad a la hora de tratar diferentes tipos de datos.\par

Por último, el Stack de Elastic, nos a ayudado mucho a ver los datos en tiempo real. El coste de trabajo de ponerla estas herramientas en producción es muy bajo con el rendimiento que obtenemos, además de la facilidad de usar Kibana para analizar los datos. \par

Dicho esto, concluimos que se han validado los requisitos propuestos por la empresa. Por su parte, Cristóbal, CTO de Movildata nos a validado el estudio realizado valorandolo muy positivamente y, de no ser por la compra de Verizon, valoraría la posibilidad de migrar a dicha arquitectura.