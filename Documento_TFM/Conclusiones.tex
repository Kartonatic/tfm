\chapter{Conclusiones y trabajo futuro}

El objetivo principal de este proyecto ha sido la elección, implementación y evaluación de una arquitectura Big Data para aplicaciones de gestión de flotas. Este trabajo se ha definido como una prueba de concepto destinado a la empresa \mdata{} para dar a conocer a dicha empresa otro tipo de arquitecturas software y herramientas que ofrece este paradigma. Aunque, durante el transcurso del proyecto, \mdata{} fuera adquirida por la multinacional Verizon, este proyecto ha tenido un grato impacto en la empresa. La arquitectura Lambda ha abierto un nuevo horizonte, ya que podemos añadir o cambiar herramientas de una forma sencilla. Además, gracias al conocimiento de nuevas herramientas se podrán proponer nuevos desarrollos que mejoren la calidad de los servicios ofrecidos.

En cuanto al trabajo realizado, se ha explorado la potencia de una arquitectura Lambda, siendo capaces de apreciar la flexibilidad de la misma y la gran capacidad de cómputo que tiene. De esta misma forma, el hecho de haber usado las herramientas expuestas ha ayudado a entender por qué están en auge en este momento, entendiendo cómo funcionan y cómo llevarlas a un plano productivo. Por su parte, que estas herramientas sean escalables horizontalmente sin tener que modificar el código que encontramos en producción es lo que hace a estas herramientas tan valiosas. Por un lado, encontramos Docker que, aunque la curva de aprendizaje es alta al principio, nos permitirá crear diferentes servicios totalmente portables. Por otro lado, encontramos Apache Hadoop, que nos proporciona escalar el almacenamiento, tan solo añadiendo nuevas máquinas de forma transparente al usuario final. Apache Spark, por su parte, nos permite realizar un procesamiento en Streaming realmente eficiente pudiendo distribuir el trabajo en diferentes zonas, incluso haciendo uso del mismo cluster de Apache Hadoop, todo esto, sin cambiar el código que tengamos en producción. Apache Kafka, nos proporcionará un sistema de acceso a los datos en streaming realmente rápido, pudiendo leer los mismos datos con diferentes procesos según el propósito. Por su parte, MongoDB nos ha proporcionado una gran cantidad de funciones geoespaciales para realizar consultas y, además de esto, el hecho de que nos retorne JSON la hace muy apropiada para su uso en diferentes aplicaciones, principalmente en aplicaciones web. En este mismo orden, el Stack de Elastic nos proporciona una gran cantidad de herramientas para controlar los flujos de datos e insertarlos en Elasticsearch proporcionando, además, una herramienta de visualización capaz de manejar gran cantidad de datos en tiempo real de una forma muy cómoda. Para terminar, otra característica importante de estas herramientas es la cantidad de librerías que tienen para distintos lenguajes, lo que nos ha facilitado el desarrollo de las mismas para usar el mismo lenguaje de programación en cada una de ellas.

Concluimos con que este paradigma encaja muy bien en este tipo de aplicaciones, en concreto, la arquitectura Lambda, que nos proporciona la capacidad de procesamiento en dos líneas que necesitan las empresas del sector. Además, las herramientas elegidas son más que aptas para aumentar la cantidad de datos que se recogen permitiendo, de igual manera, aumentar la capacidad de cómputo fácilmente.

En cuanto a los inconvenientes encontrados, el principal fue el tener que desarrollar dicha arquitectura sobre un hardware reducido. El hecho de usar dicho hardware ha implicado no tener un tiempo de respuesta óptimo ya que, debido a que los diferentes servicios tienen que estar esperando su slot de CPU y reservar su espacio de memoria, la simulación del cluster se ha visto afectada. Por otro lado, aunque menor, el hecho de que Apache Spark no tenga tipos y funciones geográficas para procesar los datos ha supuesto la implementación de las mismas, dejando de lado la orientación de los vehículos a la hora de procesarlos. Otro de los inconvenientes encontrados ha sido el hecho de tener que realizar peticiones a una base de datos externa en tiempo real, en nuestro caso a MongoDB. Tener que realizar gran cantidad de consultas geográficas ralentiza mucho el proceso, implicando que tengamos que barajar la posibilidad de modificar el proceso y pasarlo a la Batch Layer.

Una de las mayores dificultades presentadas en este proyecto fue la curva de aprendizaje de Docker. Dicha herramienta es costosa de aprender ya que tiene una gran cantidad de opciones a la hora de montar diferentes imágenes. La fase más costosa del proyecto fue la de montar Hadoop dado que, al estar aprendiendo Docker, montar un cluster que se comunicara realizando la redirección de direcciones de red, no fue tarea fácil. Por otra parte, supuso una dificultad que las contenedores no tuvieran persistencia por defecto, ya que se debían crear volúmenes o mapear los directorios con los del sistema operativo. Dicho esto, una vez aprendido, me ha resultado más ágil de usar que creando máquinas virtuales.

Además de esto, encontramos que, gracias al Máster Inter-Universitario en Tecnologías de Análisis de Datos Masivos, he sido capaz de realizar, de manera ágil y efectiva, el código necesario para llevar a cabo la pequeña aplicación de prueba. Gracias a los conceptos aprendidos en este máster, la búsqueda de herramientas y poder entender rápidamente  los conceptos que se presentan en la documentación de las herramientas, el trabajo se ha podido llevar a cabo de una forma satisfactoria.

Por último, comentar algunas futuras mejoras que se realizarán sobre esta prueba de concepto. Como primera mejora sería migrar nuestra plataforma a Kubernetes comprobando cómo se comporta, de forma que introducir nuevas máquinas, sea más fácil. Por otro lado, también se pretende introducir la arquitectura en un cluster, valorando entre los diferentes precios que se nos proponen en el mercado, para ver cómo se comporta la plataforma en un cluster real. En cuanto a la funcionalidad, se pretende añadir la dirección a la que va el vehículo para mejorar la detección de llegada a un punto. Además de esto, se pretende introducir un sistema de alarmas capaz de comunicar, en tiempo real, incidencias vía SMS, correo electrónico o con una notificación de una aplicación. En cuanto a la parte de detección de exceso de velocidad, se pretende realizar pruebas con un cluster distribuido de MongoDB, y cambiar el código de integración de mapas para que indexe los puntos geográficos mejorando el tiempo de respuesta. Por último, se pretende introducir el flujo de datos en las colas de Kafka y realizar el procesamiento.

%%% Local variables:
%%% TeX-master: "main.tex"
%%% coding: utf-8
%%% ispell-local-dictionary: "spanish"
%%% TeX-parse-self: t
%%% TeX-auto-save: t
%%% fill-column: 75
%%% End:
