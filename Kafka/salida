Attaching to zoo3, zoo1, namenode, zoo2, resourcemanager, historyserver, datanode3, datanode2, datanode1, kafka1, kafka2, kafka3, proxyserver, nodemanager, checkpointnode
[36mzoo3               |[0m  * Starting OpenBSD Secure Shell server sshd
[33mzoo1               |[0m  * Starting OpenBSD Secure Shell server sshd
[33mzoo1               |[0m    ...done.
[33mzoo1               |[0m ZooKeeper JMX enabled by default
[33mzoo1               |[0m Using config: /opt/zookeeper/bin/../conf/zoo.cfg
[33mzoo1               |[0m 2018-04-27 08:52:34,039 [myid:] - INFO  [main:QuorumPeerConfig@134] - Reading configuration from: /opt/zookeeper/bin/../conf/zoo.cfg
[36mzoo3               |[0m    ...done.
[33mzoo1               |[0m 2018-04-27 08:52:34,042 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[36mzoo3               |[0m ZooKeeper JMX enabled by default
[32mnamenode           |[0m  * Starting OpenBSD Secure Shell server sshd
[32mnamenode           |[0m    ...done.
[32mnamenode           |[0m namenode is running as process 31.  Stop it first.
[32mnamenode           |[0m 2018-04-27 08:52:34,820 INFO namenode.NameNode: STARTUP_MSG: 
[32mnamenode           |[0m /************************************************************
[32mnamenode           |[0m STARTUP_MSG: Starting NameNode
[32mnamenode           |[0m STARTUP_MSG:   host = namenode/172.28.0.2
[32mnamenode           |[0m STARTUP_MSG:   args = []
[32mnamenode           |[0m STARTUP_MSG:   version = 3.1.0
[36mzoo3               |[0m Using config: /opt/zookeeper/bin/../conf/zoo.cfg
[36mzoo3               |[0m 2018-04-27 08:52:33,390 [myid:] - INFO  [main:QuorumPeerConfig@134] - Reading configuration from: /opt/zookeeper/bin/../conf/zoo.cfg
[33mzoo1               |[0m 2018-04-27 08:52:34,042 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0
[36mzoo3               |[0m 2018-04-27 08:52:33,393 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[33mzoo1               |[0m 2018-04-27 08:52:34,042 [myid:] - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled.
[32mnamenode           |[0m STARTUP_MSG:   classpath = /opt/bd/hadoop-3.1.0/etc/hadoop:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/re2j-1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/hadoop-auth-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/asm-5.0.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-io-2.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/paranamer-2.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/json-smart-2.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/xz-1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-net-3.6.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/avro-1.7.7.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/guava-11.0.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/gson-2.2.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jettison-1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/junit-4.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/hadoop-annotations-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/hadoop-nfs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/hadoop-kms-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/hadoop-common-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/hadoop-common-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/hadoop-auth-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/xz-1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/hadoop-annotations-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/fst-2.50.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/guice-4.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-services-api-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-api-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-common-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-router-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-registry-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-common-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-client-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-services-core-3.1.0.jar
[32mnamenode           |[0m STARTUP_MSG:   build = https://github.com/apache/hadoop -r 16b70619a24cdcf5d3b0fcf4b58ca77238ccbe6d; compiled by 'centos' on 2018-03-30T00:00Z
[32mnamenode           |[0m STARTUP_MSG:   java = 1.8.0_162
[32mnamenode           |[0m ************************************************************/
[32mnamenode           |[0m 2018-04-27 08:52:34,827 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
[32mnamenode           |[0m 2018-04-27 08:52:34,830 INFO namenode.NameNode: createNameNode []
[32mnamenode           |[0m 2018-04-27 08:52:35,063 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[32mnamenode           |[0m 2018-04-27 08:52:35,122 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[32mnamenode           |[0m 2018-04-27 08:52:35,122 INFO impl.MetricsSystemImpl: NameNode metrics system started
[32mnamenode           |[0m 2018-04-27 08:52:35,137 INFO namenode.NameNode: fs.defaultFS is hdfs://namenode:9000/
[32mnamenode           |[0m 2018-04-27 08:52:35,141 INFO namenode.NameNode: Clients are to use namenode:9000 to access this namenode/service.
[32mnamenode           |[0m 2018-04-27 08:52:35,281 INFO util.JvmPauseMonitor: Starting JVM pause monitor
[32mnamenode           |[0m 2018-04-27 08:52:35,294 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://namenode:50070
[32mnamenode           |[0m 2018-04-27 08:52:35,306 INFO util.log: Logging initialized @885ms
[32mnamenode           |[0m 2018-04-27 08:52:35,368 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
[32mnamenode           |[0m 2018-04-27 08:52:35,376 INFO http.HttpRequestLog: Http request log for http.requests.namenode is not defined
[32mnamenode           |[0m 2018-04-27 08:52:35,383 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[32mnamenode           |[0m 2018-04-27 08:52:35,385 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
[32mnamenode           |[0m 2018-04-27 08:52:35,385 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[32mnamenode           |[0m 2018-04-27 08:52:35,386 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[32mnamenode           |[0m 2018-04-27 08:52:35,400 INFO http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
[32mnamenode           |[0m 2018-04-27 08:52:35,400 INFO http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
[36mzoo3               |[0m 2018-04-27 08:52:33,394 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0
[33mzoo1               |[0m 2018-04-27 08:52:34,042 [myid:] - WARN  [main:QuorumPeerMain@113] - Either no config or no quorum defined in config, running  in standalone mode
[31mresourcemanager    |[0m  * Starting OpenBSD Secure Shell server sshd
[31mresourcemanager    |[0m    ...done.
[33mzoo1               |[0m 2018-04-27 08:52:34,050 [myid:] - INFO  [main:QuorumPeerConfig@134] - Reading configuration from: /opt/zookeeper/bin/../conf/zoo.cfg
[31mresourcemanager    |[0m resourcemanager is running as process 28.  Stop it first.
[32mnamenode           |[0m 2018-04-27 08:52:35,406 INFO http.HttpServer2: Jetty bound to port 50070
[35mzoo2               |[0m  * Starting OpenBSD Secure Shell server sshd
[36mzoo3               |[0m 2018-04-27 08:52:33,394 [myid:] - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled.
[33mzoo1               |[0m 2018-04-27 08:52:34,050 [myid:] - INFO  [main:ZooKeeperServerMain@96] - Starting server
[35mzoo2               |[0m    ...done.
[36mzoo3               |[0m 2018-04-27 08:52:33,394 [myid:] - WARN  [main:QuorumPeerMain@113] - Either no config or no quorum defined in config, running  in standalone mode
[35mzoo2               |[0m ZooKeeper JMX enabled by default
[34mhistoryserver      |[0m  * Starting OpenBSD Secure Shell server sshd
[36mzoo3               |[0m 2018-04-27 08:52:33,401 [myid:] - INFO  [main:QuorumPeerConfig@134] - Reading configuration from: /opt/zookeeper/bin/../conf/zoo.cfg
[35mzoo2               |[0m Using config: /opt/zookeeper/bin/../conf/zoo.cfg
[32mnamenode           |[0m 2018-04-27 08:52:35,407 INFO server.Server: jetty-9.3.19.v20170502
[33mzoo1               |[0m 2018-04-27 08:52:34,055 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
[35mzoo2               |[0m 2018-04-27 08:52:34,931 [myid:] - INFO  [main:QuorumPeerConfig@134] - Reading configuration from: /opt/zookeeper/bin/../conf/zoo.cfg
[36mzoo3               |[0m 2018-04-27 08:52:33,402 [myid:] - INFO  [main:ZooKeeperServerMain@96] - Starting server
[34mhistoryserver      |[0m    ...done.
[36;1mdatanode3          |[0m  * Starting OpenBSD Secure Shell server sshd
[32mnamenode           |[0m 2018-04-27 08:52:35,426 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@28dcca0c{/logs,file:///var/log/hadoop/hdfs/,AVAILABLE}
[36;1mdatanode3          |[0m    ...done.
[33mzoo1               |[0m 2018-04-27 08:52:34,055 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=zoo1
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
[32mnamenode           |[0m 2018-04-27 08:52:35,427 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@52f27fbd{/static,file:///opt/bd/hadoop-3.1.0/share/hadoop/hdfs/webapps/static/,AVAILABLE}
[33mzoo1               |[0m 2018-04-27 08:52:34,055 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.8.0_162
[36;1mdatanode3          |[0m datanode is running as process 30.  Stop it first.
[31mresourcemanager exited with code 1
[0m[33mzoo1               |[0m 2018-04-27 08:52:34,055 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=zoo3
[34mhistoryserver      |[0m historyserver is running as process 29.  Stop it first.
[32mnamenode           |[0m 2018-04-27 08:52:35,471 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@19b843ba{/,file:///opt/bd/hadoop-3.1.0/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}
[33mzoo1               |[0m 2018-04-27 08:52:34,055 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
[32mnamenode           |[0m 2018-04-27 08:52:35,476 INFO server.AbstractConnector: Started ServerConnector@2f666ebb{HTTP/1.1,[http/1.1]}{namenode:50070}
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.8.0_162
[33mzoo1               |[0m 2018-04-27 08:52:34,056 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper/bin/../build/classes:/opt/zookeeper/bin/../build/lib/*.jar:/opt/zookeeper/bin/../lib/slf4j-log4j12-1.6.1.jar:/opt/zookeeper/bin/../lib/slf4j-api-1.6.1.jar:/opt/zookeeper/bin/../lib/netty-3.10.5.Final.jar:/opt/zookeeper/bin/../lib/log4j-1.2.16.jar:/opt/zookeeper/bin/../lib/jline-0.9.94.jar:/opt/zookeeper/bin/../zookeeper-3.4.10.jar:/opt/zookeeper/bin/../src/java/lib/*.jar:/opt/zookeeper/bin/../conf:
[35mzoo2               |[0m 2018-04-27 08:52:34,936 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[35mzoo2               |[0m 2018-04-27 08:52:34,936 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0
[32mnamenode           |[0m 2018-04-27 08:52:35,476 INFO server.Server: Started @1056ms
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
[32;1mdatanode1          |[0m  * Starting OpenBSD Secure Shell server sshd
[33mzoo1               |[0m 2018-04-27 08:52:34,056 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[35mzoo2               |[0m 2018-04-27 08:52:34,937 [myid:] - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled.
[32;1mdatanode1          |[0m    ...done.
[32;1mdatanode1          |[0m datanode is running as process 31.  Stop it first.
[33mzoo1               |[0m 2018-04-27 08:52:34,056 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[33;1mdatanode2          |[0m  * Starting OpenBSD Secure Shell server sshd
[34mhistoryserver exited with code 1
[0m[33mzoo1               |[0m 2018-04-27 08:52:34,056 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[36;1mdatanode3 exited with code 1
[0m[32mnamenode           |[0m 2018-04-27 08:52:35,609 WARN namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
[32mnamenode           |[0m 2018-04-27 08:52:35,609 WARN namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
[35;1mkafka1             |[0m  * Starting OpenBSD Secure Shell server sshd
[35;1mkafka1             |[0m    ...done.
[35mzoo2               |[0m 2018-04-27 08:52:34,937 [myid:] - WARN  [main:QuorumPeerMain@113] - Either no config or no quorum defined in config, running  in standalone mode
[33;1mdatanode2          |[0m    ...done.
[32;1mdatanode1 exited with code 1
[0m[35;1mkafka1             |[0m [2018-04-27 08:52:45,202] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[33mzoo1               |[0m 2018-04-27 08:52:34,057 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,044 INFO datanode.DataNode: STARTUP_MSG: 
[33;1mdatanode2          |[0m /************************************************************
[33;1mdatanode2          |[0m STARTUP_MSG: Starting DataNode
[33;1mdatanode2          |[0m STARTUP_MSG:   host = datanode2/172.28.0.9
[33;1mdatanode2          |[0m STARTUP_MSG:   args = []
[33;1mdatanode2          |[0m STARTUP_MSG:   version = 3.1.0
[33;1mdatanode2          |[0m STARTUP_MSG:   classpath = /opt/bd/hadoop-3.1.0/etc/hadoop:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/re2j-1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/hadoop-auth-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/asm-5.0.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-io-2.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/paranamer-2.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/json-smart-2.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/xz-1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-net-3.6.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/avro-1.7.7.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/guava-11.0.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/gson-2.2.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jettison-1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/junit-4.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/hadoop-annotations-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/hadoop-nfs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/hadoop-kms-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/hadoop-common-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/common/hadoop-common-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/hadoop-auth-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/xz-1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/hadoop-annotations-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/fst-2.50.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/guice-4.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-services-api-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-api-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-common-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-router-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-registry-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-common-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-client-3.1.0.jar:/opt/bd/hadoop-3.1.0/share/hadoop/yarn/hadoop-yarn-services-core-3.1.0.jar
[33;1mdatanode2          |[0m STARTUP_MSG:   build = https://github.com/apache/hadoop -r 16b70619a24cdcf5d3b0fcf4b58ca77238ccbe6d; compiled by 'centos' on 2018-03-30T00:00Z
[33;1mdatanode2          |[0m STARTUP_MSG:   java = 1.8.0_162
[33;1mdatanode2          |[0m ************************************************************/
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper/bin/../build/classes:/opt/zookeeper/bin/../build/lib/*.jar:/opt/zookeeper/bin/../lib/slf4j-log4j12-1.6.1.jar:/opt/zookeeper/bin/../lib/slf4j-api-1.6.1.jar:/opt/zookeeper/bin/../lib/netty-3.10.5.Final.jar:/opt/zookeeper/bin/../lib/log4j-1.2.16.jar:/opt/zookeeper/bin/../lib/jline-0.9.94.jar:/opt/zookeeper/bin/../zookeeper-3.4.10.jar:/opt/zookeeper/bin/../src/java/lib/*.jar:/opt/zookeeper/bin/../conf:
[35mzoo2               |[0m 2018-04-27 08:52:34,947 [myid:] - INFO  [main:QuorumPeerConfig@134] - Reading configuration from: /opt/zookeeper/bin/../conf/zoo.cfg
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,051 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
[35;1mkafka1             |[0m [2018-04-27 08:52:45,639] INFO starting (kafka.server.KafkaServer)
[35mzoo2               |[0m 2018-04-27 08:52:34,948 [myid:] - INFO  [main:ZooKeeperServerMain@96] - Starting server
[35mzoo2               |[0m 2018-04-27 08:52:34,953 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
[34;1mkafka3             |[0m  * Starting OpenBSD Secure Shell server sshd
[34;1mkafka3             |[0m    ...done.
[34;1mkafka3             |[0m [2018-04-27 08:52:48,052] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,463] INFO starting (kafka.server.KafkaServer)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,464] INFO Connecting to zookeeper on zoo1:2181,zoo2:2181,zoo3:2181 (kafka.server.KafkaServer)
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,466 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/var/data/hadoop/hdfs/dn
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[35;1mkafka1             |[0m [2018-04-27 08:52:45,640] INFO Connecting to zookeeper on zoo1:2181,zoo2:2181,zoo3:2181 (kafka.server.KafkaServer)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,654] INFO [ZooKeeperClient] Initializing a new session to zoo1:2181,zoo2:2181,zoo3:2181. (kafka.zookeeper.ZooKeeperClient)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:host.name=kafka1 (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:java.version=1.8.0_162 (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[31;1mkafka2             |[0m  * Starting OpenBSD Secure Shell server sshd
[33mzoo1               |[0m 2018-04-27 08:52:34,057 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[32mnamenode           |[0m 2018-04-27 08:52:35,640 INFO namenode.FSEditLog: Edit logging is async:true
[36mzoo3               |[0m 2018-04-27 08:52:33,407 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[35mzoo2               |[0m 2018-04-27 08:52:34,954 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=zoo2
[34;1mkafka3             |[0m [2018-04-27 08:52:48,478] INFO [ZooKeeperClient] Initializing a new session to zoo1:2181,zoo2:2181,zoo3:2181. (kafka.zookeeper.ZooKeeperClient)
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,813 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,853 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,853 INFO impl.MetricsSystemImpl: DataNode metrics system started
[35mzoo2               |[0m 2018-04-27 08:52:34,954 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.8.0_162
[33mzoo1               |[0m 2018-04-27 08:52:34,057 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=4.13.0-39-generic
[36mzoo3               |[0m 2018-04-27 08:52:33,408 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:java.class.path=/opt/kafka//bin/../libs/aopalliance-repackaged-2.5.0-b32.jar:/opt/kafka//bin/../libs/argparse4j-0.7.0.jar:/opt/kafka//bin/../libs/commons-lang3-3.5.jar:/opt/kafka//bin/../libs/connect-api-1.1.0.jar:/opt/kafka//bin/../libs/connect-file-1.1.0.jar:/opt/kafka//bin/../libs/connect-json-1.1.0.jar:/opt/kafka//bin/../libs/connect-runtime-1.1.0.jar:/opt/kafka//bin/../libs/connect-transforms-1.1.0.jar:/opt/kafka//bin/../libs/guava-20.0.jar:/opt/kafka//bin/../libs/hk2-api-2.5.0-b32.jar:/opt/kafka//bin/../libs/hk2-locator-2.5.0-b32.jar:/opt/kafka//bin/../libs/hk2-utils-2.5.0-b32.jar:/opt/kafka//bin/../libs/jackson-annotations-2.9.4.jar:/opt/kafka//bin/../libs/jackson-core-2.9.4.jar:/opt/kafka//bin/../libs/jackson-databind-2.9.4.jar:/opt/kafka//bin/../libs/jackson-jaxrs-base-2.9.4.jar:/opt/kafka//bin/../libs/jackson-jaxrs-json-provider-2.9.4.jar:/opt/kafka//bin/../libs/jackson-module-jaxb-annotations-2.9.4.jar:/opt/kafka//bin/../libs/javassist-3.20.0-GA.jar:/opt/kafka//bin/../libs/javassist-3.21.0-GA.jar:/opt/kafka//bin/../libs/javax.annotation-api-1.2.jar:/opt/kafka//bin/../libs/javax.inject-1.jar:/opt/kafka//bin/../libs/javax.inject-2.5.0-b32.jar:/opt/kafka//bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka//bin/../libs/javax.ws.rs-api-2.0.1.jar:/opt/kafka//bin/../libs/jersey-client-2.25.1.jar:/opt/kafka//bin/../libs/jersey-common-2.25.1.jar:/opt/kafka//bin/../libs/jersey-container-servlet-2.25.1.jar:/opt/kafka//bin/../libs/jersey-container-servlet-core-2.25.1.jar:/opt/kafka//bin/../libs/jersey-guava-2.25.1.jar:/opt/kafka//bin/../libs/jersey-media-jaxb-2.25.1.jar:/opt/kafka//bin/../libs/jersey-server-2.25.1.jar:/opt/kafka//bin/../libs/jetty-client-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-continuation-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-http-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-io-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-security-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-server-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-servlet-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-servlets-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-util-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka//bin/../libs/kafka-clients-1.1.0.jar:/opt/kafka//bin/../libs/kafka-log4j-appender-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-examples-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-test-utils-1.1.0.jar:/opt/kafka//bin/../libs/kafka-tools-1.1.0.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0-sources.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0-test-sources.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0.jar:/opt/kafka//bin/../libs/log4j-1.2.17.jar:/opt/kafka//bin/../libs/lz4-java-1.4.jar:/opt/kafka//bin/../libs/maven-artifact-3.5.2.jar:/opt/kafka//bin/../libs/metrics-core-2.2.0.jar:/opt/kafka//bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka//bin/../libs/plexus-utils-3.1.0.jar:/opt/kafka//bin/../libs/reflections-0.9.11.jar:/opt/kafka//bin/../libs/rocksdbjni-5.7.3.jar:/opt/kafka//bin/../libs/scala-library-2.12.4.jar:/opt/kafka//bin/../libs/scala-logging_2.12-3.7.2.jar:/opt/kafka//bin/../libs/scala-reflect-2.12.4.jar:/opt/kafka//bin/../libs/slf4j-api-1.7.25.jar:/opt/kafka//bin/../libs/slf4j-log4j12-1.7.25.jar:/opt/kafka//bin/../libs/snappy-java-1.1.7.1.jar:/opt/kafka//bin/../libs/validation-api-1.1.0.Final.jar:/opt/kafka//bin/../libs/zkclient-0.10.jar:/opt/kafka//bin/../libs/zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,970 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[36mproxyserver        |[0m  * Starting OpenBSD Secure Shell server sshd
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[32mnamenode           |[0m 2018-04-27 08:52:35,678 INFO namenode.FSNamesystem: KeyProvider: null
[31;1mkafka2             |[0m    ...done.
[34;1mkafka3             |[0m [2018-04-27 08:52:48,482] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,482] INFO Client environment:host.name=kafka3 (org.apache.zookeeper.ZooKeeper)
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,972 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
[32mnamenode           |[0m 2018-04-27 08:52:35,679 INFO namenode.FSNamesystem: fsLock is fair: true
[33mnodemanager        |[0m  * Starting OpenBSD Secure Shell server sshd
[33mnodemanager        |[0m    ...done.
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,976 INFO datanode.DataNode: Configured hostname is datanode2
[35mzoo2               |[0m 2018-04-27 08:52:34,954 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[32mnamenode           |[0m 2018-04-27 08:52:35,681 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
[36mproxyserver        |[0m    ...done.
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,976 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,979 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0
[35mzoo2               |[0m 2018-04-27 08:52:34,954 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
[32mnamenode           |[0m 2018-04-27 08:52:35,685 INFO namenode.FSNamesystem: fsOwner             = hdmaster (auth:SIMPLE)
[32mnamenode           |[0m 2018-04-27 08:52:35,686 INFO namenode.FSNamesystem: supergroup          = supergroup
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:java.version=1.8.0_162 (org.apache.zookeeper.ZooKeeper)
[32mcheckpointnode     |[0m  * Starting OpenBSD Secure Shell server sshd
[33mzoo1               |[0m 2018-04-27 08:52:34,057 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=hdmaster
[36mzoo3               |[0m 2018-04-27 08:52:33,409 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[33mnodemanager        |[0m nodemanager is running as process 29.  Stop it first.
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,659] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,997 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,999 INFO datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
[33;1mdatanode2          |[0m 2018-04-27 08:52:43,999 INFO datanode.DataNode: Number threads for balancing is 50
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,036 INFO util.log: Logging initialized @1386ms
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,156 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,158 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,660] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[33mzoo1               |[0m 2018-04-27 08:52:34,057 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/opt/bd
[33mzoo1               |[0m 2018-04-27 08:52:34,057 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/
[33mzoo1               |[0m 2018-04-27 08:52:34,061 [myid:] - INFO  [main:ZooKeeperServer@829] - tickTime set to 2000
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[36mzoo3               |[0m 2018-04-27 08:52:33,409 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=4.13.0-39-generic
[31;1mkafka2             |[0m [2018-04-27 08:52:46,282] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,162 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[36mproxyserver        |[0m proxyserver is running as process 29.  Stop it first.
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:java.class.path=/opt/kafka//bin/../libs/aopalliance-repackaged-2.5.0-b32.jar:/opt/kafka//bin/../libs/argparse4j-0.7.0.jar:/opt/kafka//bin/../libs/commons-lang3-3.5.jar:/opt/kafka//bin/../libs/connect-api-1.1.0.jar:/opt/kafka//bin/../libs/connect-file-1.1.0.jar:/opt/kafka//bin/../libs/connect-json-1.1.0.jar:/opt/kafka//bin/../libs/connect-runtime-1.1.0.jar:/opt/kafka//bin/../libs/connect-transforms-1.1.0.jar:/opt/kafka//bin/../libs/guava-20.0.jar:/opt/kafka//bin/../libs/hk2-api-2.5.0-b32.jar:/opt/kafka//bin/../libs/hk2-locator-2.5.0-b32.jar:/opt/kafka//bin/../libs/hk2-utils-2.5.0-b32.jar:/opt/kafka//bin/../libs/jackson-annotations-2.9.4.jar:/opt/kafka//bin/../libs/jackson-core-2.9.4.jar:/opt/kafka//bin/../libs/jackson-databind-2.9.4.jar:/opt/kafka//bin/../libs/jackson-jaxrs-base-2.9.4.jar:/opt/kafka//bin/../libs/jackson-jaxrs-json-provider-2.9.4.jar:/opt/kafka//bin/../libs/jackson-module-jaxb-annotations-2.9.4.jar:/opt/kafka//bin/../libs/javassist-3.20.0-GA.jar:/opt/kafka//bin/../libs/javassist-3.21.0-GA.jar:/opt/kafka//bin/../libs/javax.annotation-api-1.2.jar:/opt/kafka//bin/../libs/javax.inject-1.jar:/opt/kafka//bin/../libs/javax.inject-2.5.0-b32.jar:/opt/kafka//bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka//bin/../libs/javax.ws.rs-api-2.0.1.jar:/opt/kafka//bin/../libs/jersey-client-2.25.1.jar:/opt/kafka//bin/../libs/jersey-common-2.25.1.jar:/opt/kafka//bin/../libs/jersey-container-servlet-2.25.1.jar:/opt/kafka//bin/../libs/jersey-container-servlet-core-2.25.1.jar:/opt/kafka//bin/../libs/jersey-guava-2.25.1.jar:/opt/kafka//bin/../libs/jersey-media-jaxb-2.25.1.jar:/opt/kafka//bin/../libs/jersey-server-2.25.1.jar:/opt/kafka//bin/../libs/jetty-client-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-continuation-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-http-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-io-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-security-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-server-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-servlet-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-servlets-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-util-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka//bin/../libs/kafka-clients-1.1.0.jar:/opt/kafka//bin/../libs/kafka-log4j-appender-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-examples-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-test-utils-1.1.0.jar:/opt/kafka//bin/../libs/kafka-tools-1.1.0.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0-sources.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0-test-sources.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0.jar:/opt/kafka//bin/../libs/log4j-1.2.17.jar:/opt/kafka//bin/../libs/lz4-java-1.4.jar:/opt/kafka//bin/../libs/maven-artifact-3.5.2.jar:/opt/kafka//bin/../libs/metrics-core-2.2.0.jar:/opt/kafka//bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka//bin/../libs/plexus-utils-3.1.0.jar:/opt/kafka//bin/../libs/reflections-0.9.11.jar:/opt/kafka//bin/../libs/rocksdbjni-5.7.3.jar:/opt/kafka//bin/../libs/scala-library-2.12.4.jar:/opt/kafka//bin/../libs/scala-logging_2.12-3.7.2.jar:/opt/kafka//bin/../libs/scala-reflect-2.12.4.jar:/opt/kafka//bin/../libs/slf4j-api-1.7.25.jar:/opt/kafka//bin/../libs/slf4j-log4j12-1.7.25.jar:/opt/kafka//bin/../libs/snappy-java-1.1.7.1.jar:/opt/kafka//bin/../libs/validation-api-1.1.0.Final.jar:/opt/kafka//bin/../libs/zkclient-0.10.jar:/opt/kafka//bin/../libs/zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[33mzoo1               |[0m 2018-04-27 08:52:34,061 [myid:] - INFO  [main:ZooKeeperServer@838] - minSessionTimeout set to -1
[35mzoo2               |[0m 2018-04-27 08:52:34,954 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper/bin/../build/classes:/opt/zookeeper/bin/../build/lib/*.jar:/opt/zookeeper/bin/../lib/slf4j-log4j12-1.6.1.jar:/opt/zookeeper/bin/../lib/slf4j-api-1.6.1.jar:/opt/zookeeper/bin/../lib/netty-3.10.5.Final.jar:/opt/zookeeper/bin/../lib/log4j-1.2.16.jar:/opt/zookeeper/bin/../lib/jline-0.9.94.jar:/opt/zookeeper/bin/../zookeeper-3.4.10.jar:/opt/zookeeper/bin/../src/java/lib/*.jar:/opt/zookeeper/bin/../conf:
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,164 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[35mzoo2               |[0m 2018-04-27 08:52:34,954 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[33mzoo1               |[0m 2018-04-27 08:52:34,061 [myid:] - INFO  [main:ZooKeeperServer@847] - maxSessionTimeout set to -1
[33mzoo1               |[0m 2018-04-27 08:52:34,067 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[31;1mkafka2             |[0m [2018-04-27 08:52:46,699] INFO starting (kafka.server.KafkaServer)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,700] INFO Connecting to zookeeper on zoo1:2181,zoo2:2181,zoo3:2181 (kafka.server.KafkaServer)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,713] INFO [ZooKeeperClient] Initializing a new session to zoo1:2181,zoo2:2181,zoo3:2181. (kafka.zookeeper.ZooKeeperClient)
[33mzoo1               |[0m 2018-04-27 08:52:45,740 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /172.28.0.14:33698
[32mcheckpointnode     |[0m    ...done.
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,164 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[32mnamenode           |[0m 2018-04-27 08:52:35,686 INFO namenode.FSNamesystem: isPermissionEnabled = true
[36mzoo3               |[0m 2018-04-27 08:52:33,409 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=hdmaster
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,164 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[32mnamenode           |[0m 2018-04-27 08:52:35,686 INFO namenode.FSNamesystem: HA Enabled: false
[32mnamenode           |[0m 2018-04-27 08:52:35,717 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,183 INFO http.HttpServer2: Jetty bound to port 33479
[35mzoo2               |[0m 2018-04-27 08:52:34,954 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[35mzoo2               |[0m 2018-04-27 08:52:34,954 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[33mnodemanager exited with code 1
[0m[35;1mkafka1             |[0m [2018-04-27 08:52:45,660] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,717] INFO Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT (org.apache.zookeeper.ZooKeeper)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,717] INFO Client environment:host.name=kafka2 (org.apache.zookeeper.ZooKeeper)
[32mnamenode           |[0m 2018-04-27 08:52:35,724 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
[32mnamenode           |[0m 2018-04-27 08:52:35,724 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
[35;1mkafka1             |[0m [2018-04-27 08:52:45,660] INFO Client environment:os.version=4.13.0-39-generic (org.apache.zookeeper.ZooKeeper)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,184 INFO server.Server: jetty-9.3.19.v20170502
[35;1mkafka1             |[0m [2018-04-27 08:52:45,660] INFO Client environment:user.name=hdmaster (org.apache.zookeeper.ZooKeeper)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[36mproxyserver exited with code 1
[0m[35;1mkafka1             |[0m [2018-04-27 08:52:45,660] INFO Client environment:user.home=/opt/bd (org.apache.zookeeper.ZooKeeper)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mnamenode           |[0m 2018-04-27 08:52:35,726 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
[31;1mkafka2             |[0m [2018-04-27 08:52:46,717] INFO Client environment:java.version=1.8.0_162 (org.apache.zookeeper.ZooKeeper)
[33mzoo1               |[0m 2018-04-27 08:52:45,747 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@942] - Client attempting to establish new session at /172.28.0.14:33698
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:os.version=4.13.0-39-generic (org.apache.zookeeper.ZooKeeper)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:user.name=hdmaster (org.apache.zookeeper.ZooKeeper)
[33mzoo1               |[0m 2018-04-27 08:52:45,749 [myid:] - INFO  [SyncThread:0:FileTxnLog@203] - Creating new log file: log.1
[35mzoo2               |[0m 2018-04-27 08:52:34,956 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[32mcheckpointnode     |[0m secondarynamenode is running as process 30.  Stop it first.
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:user.home=/opt/bd (org.apache.zookeeper.ZooKeeper)
[35mzoo2               |[0m 2018-04-27 08:52:34,956 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[35mzoo2               |[0m 2018-04-27 08:52:34,956 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=4.13.0-39-generic
[35mzoo2               |[0m 2018-04-27 08:52:34,956 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=hdmaster
[36mzoo3               |[0m 2018-04-27 08:52:33,409 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/opt/bd
[32mnamenode           |[0m 2018-04-27 08:52:35,727 INFO blockmanagement.BlockManager: The block deletion will start around 2018 Apr 27 08:52:35
[32mnamenode           |[0m 2018-04-27 08:52:35,728 INFO util.GSet: Computing capacity for map BlocksMap
[32mnamenode           |[0m 2018-04-27 08:52:35,728 INFO util.GSet: VM type       = 64-bit
[34;1mkafka3             |[0m [2018-04-27 08:52:48,483] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,205 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6e4566f1{/logs,file:///var/log/hadoop/hdfs/,AVAILABLE}
[35mzoo2               |[0m 2018-04-27 08:52:34,956 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/opt/bd
[35;1mkafka1             |[0m [2018-04-27 08:52:45,660] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,205 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@344f4dea{/static,file:///opt/bd/hadoop-3.1.0/share/hadoop/hdfs/webapps/static/,AVAILABLE}
[36mzoo3               |[0m 2018-04-27 08:52:33,409 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/
[31;1mkafka2             |[0m [2018-04-27 08:52:46,717] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[32mnamenode           |[0m 2018-04-27 08:52:35,729 INFO util.GSet: 2.0% max memory 3.6 GB = 72.8 MB
[32mnamenode           |[0m 2018-04-27 08:52:35,729 INFO util.GSet: capacity      = 2^23 = 8388608 entries
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,276 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@34cdeda2{/,file:///opt/bd/hadoop-3.1.0/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
[33mzoo1               |[0m 2018-04-27 08:52:46,010 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@687] - Established session 0x163064dd49b0000 with negotiated timeout 6000 for client /172.28.0.14:33698
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,280 INFO server.AbstractConnector: Started ServerConnector@447a020{HTTP/1.1,[http/1.1]}{localhost:33479}
[35;1mkafka1             |[0m [2018-04-27 08:52:45,661] INFO Initiating client connection, connectString=zoo1:2181,zoo2:2181,zoo3:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3e92efc3 (org.apache.zookeeper.ZooKeeper)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,484] INFO Initiating client connection, connectString=zoo1:2181,zoo2:2181,zoo3:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3e92efc3 (org.apache.zookeeper.ZooKeeper)
[33mzoo1               |[0m 2018-04-27 08:52:46,168 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd49b0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
[36mzoo3               |[0m 2018-04-27 08:52:33,413 [myid:] - INFO  [main:ZooKeeperServer@829] - tickTime set to 2000
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,280 INFO server.Server: Started @1630ms
[31;1mkafka2             |[0m [2018-04-27 08:52:46,717] INFO Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre (org.apache.zookeeper.ZooKeeper)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,717] INFO Client environment:java.class.path=/opt/kafka//bin/../libs/aopalliance-repackaged-2.5.0-b32.jar:/opt/kafka//bin/../libs/argparse4j-0.7.0.jar:/opt/kafka//bin/../libs/commons-lang3-3.5.jar:/opt/kafka//bin/../libs/connect-api-1.1.0.jar:/opt/kafka//bin/../libs/connect-file-1.1.0.jar:/opt/kafka//bin/../libs/connect-json-1.1.0.jar:/opt/kafka//bin/../libs/connect-runtime-1.1.0.jar:/opt/kafka//bin/../libs/connect-transforms-1.1.0.jar:/opt/kafka//bin/../libs/guava-20.0.jar:/opt/kafka//bin/../libs/hk2-api-2.5.0-b32.jar:/opt/kafka//bin/../libs/hk2-locator-2.5.0-b32.jar:/opt/kafka//bin/../libs/hk2-utils-2.5.0-b32.jar:/opt/kafka//bin/../libs/jackson-annotations-2.9.4.jar:/opt/kafka//bin/../libs/jackson-core-2.9.4.jar:/opt/kafka//bin/../libs/jackson-databind-2.9.4.jar:/opt/kafka//bin/../libs/jackson-jaxrs-base-2.9.4.jar:/opt/kafka//bin/../libs/jackson-jaxrs-json-provider-2.9.4.jar:/opt/kafka//bin/../libs/jackson-module-jaxb-annotations-2.9.4.jar:/opt/kafka//bin/../libs/javassist-3.20.0-GA.jar:/opt/kafka//bin/../libs/javassist-3.21.0-GA.jar:/opt/kafka//bin/../libs/javax.annotation-api-1.2.jar:/opt/kafka//bin/../libs/javax.inject-1.jar:/opt/kafka//bin/../libs/javax.inject-2.5.0-b32.jar:/opt/kafka//bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka//bin/../libs/javax.ws.rs-api-2.0.1.jar:/opt/kafka//bin/../libs/jersey-client-2.25.1.jar:/opt/kafka//bin/../libs/jersey-common-2.25.1.jar:/opt/kafka//bin/../libs/jersey-container-servlet-2.25.1.jar:/opt/kafka//bin/../libs/jersey-container-servlet-core-2.25.1.jar:/opt/kafka//bin/../libs/jersey-guava-2.25.1.jar:/opt/kafka//bin/../libs/jersey-media-jaxb-2.25.1.jar:/opt/kafka//bin/../libs/jersey-server-2.25.1.jar:/opt/kafka//bin/../libs/jetty-client-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-continuation-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-http-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-io-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-security-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-server-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-servlet-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-servlets-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jetty-util-9.2.24.v20180105.jar:/opt/kafka//bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka//bin/../libs/kafka-clients-1.1.0.jar:/opt/kafka//bin/../libs/kafka-log4j-appender-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-examples-1.1.0.jar:/opt/kafka//bin/../libs/kafka-streams-test-utils-1.1.0.jar:/opt/kafka//bin/../libs/kafka-tools-1.1.0.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0-sources.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0-test-sources.jar:/opt/kafka//bin/../libs/kafka_2.12-1.1.0.jar:/opt/kafka//bin/../libs/log4j-1.2.17.jar:/opt/kafka//bin/../libs/lz4-java-1.4.jar:/opt/kafka//bin/../libs/maven-artifact-3.5.2.jar:/opt/kafka//bin/../libs/metrics-core-2.2.0.jar:/opt/kafka//bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka//bin/../libs/plexus-utils-3.1.0.jar:/opt/kafka//bin/../libs/reflections-0.9.11.jar:/opt/kafka//bin/../libs/rocksdbjni-5.7.3.jar:/opt/kafka//bin/../libs/scala-library-2.12.4.jar:/opt/kafka//bin/../libs/scala-logging_2.12-3.7.2.jar:/opt/kafka//bin/../libs/scala-reflect-2.12.4.jar:/opt/kafka//bin/../libs/slf4j-api-1.7.25.jar:/opt/kafka//bin/../libs/slf4j-log4j12-1.7.25.jar:/opt/kafka//bin/../libs/snappy-java-1.1.7.1.jar:/opt/kafka//bin/../libs/validation-api-1.1.0.Final.jar:/opt/kafka//bin/../libs/zkclient-0.10.jar:/opt/kafka//bin/../libs/zookeeper-3.4.10.jar (org.apache.zookeeper.ZooKeeper)
[35mzoo2               |[0m 2018-04-27 08:52:34,956 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/
[32mnamenode           |[0m 2018-04-27 08:52:35,735 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
[35;1mkafka1             |[0m [2018-04-27 08:52:45,735] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[33mzoo1               |[0m 2018-04-27 08:52:46,712 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd49b0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
[34;1mkafka3             |[0m [2018-04-27 08:52:48,498] INFO Opening socket connection to server zoo2.kafka_kafkaNet/172.28.0.12:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,376 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
[34;1mkafka3             |[0m [2018-04-27 08:52:48,498] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[35mzoo2               |[0m 2018-04-27 08:52:34,961 [myid:] - INFO  [main:ZooKeeperServer@829] - tickTime set to 2000
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:45,735] INFO Opening socket connection to server zoo1.kafka_kafkaNet/172.28.0.11:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36mzoo3               |[0m 2018-04-27 08:52:33,413 [myid:] - INFO  [main:ZooKeeperServer@838] - minSessionTimeout set to -1
[35mzoo2               |[0m 2018-04-27 08:52:34,961 [myid:] - INFO  [main:ZooKeeperServer@838] - minSessionTimeout set to -1
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
[33mzoo1               |[0m 2018-04-27 08:52:46,941 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd49b0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManager: defaultReplication         = 2
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManager: maxReplication             = 512
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManager: minReplication             = 1
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,380 INFO util.JvmPauseMonitor: Starting JVM pause monitor
[35;1mkafka1             |[0m [2018-04-27 08:52:45,739] INFO Socket connection established to zoo1.kafka_kafkaNet/172.28.0.11:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,501] INFO Socket connection established to zoo2.kafka_kafkaNet/172.28.0.12:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[34;1mkafka3             |[0m [2018-04-27 08:52:48,744] INFO Session establishment complete on server zoo2.kafka_kafkaNet/172.28.0.12:2181, sessionid = 0x163064dd8230000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36mzoo3               |[0m 2018-04-27 08:52:33,413 [myid:] - INFO  [main:ZooKeeperServer@847] - maxSessionTimeout set to -1
[32mnamenode           |[0m 2018-04-27 08:52:35,740 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
[35;1mkafka1             |[0m [2018-04-27 08:52:46,012] INFO Session establishment complete on server zoo1.kafka_kafkaNet/172.28.0.11:2181, sessionid = 0x163064dd49b0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[32mnamenode           |[0m 2018-04-27 08:52:35,766 INFO util.GSet: Computing capacity for map INodeMap
[32mnamenode           |[0m 2018-04-27 08:52:35,766 INFO util.GSet: VM type       = 64-bit
[32mnamenode           |[0m 2018-04-27 08:52:35,766 INFO util.GSet: 1.0% max memory 3.6 GB = 36.4 MB
[32mnamenode           |[0m 2018-04-27 08:52:35,766 INFO util.GSet: capacity      = 2^22 = 4194304 entries
[32mnamenode           |[0m 2018-04-27 08:52:35,767 INFO namenode.FSDirectory: ACLs enabled? false
[32mnamenode           |[0m 2018-04-27 08:52:35,767 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
[35mzoo2               |[0m 2018-04-27 08:52:34,961 [myid:] - INFO  [main:ZooKeeperServer@847] - maxSessionTimeout set to -1
[34;1mkafka3             |[0m [2018-04-27 08:52:48,747] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[35;1mkafka1             |[0m [2018-04-27 08:52:46,016] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:os.version=4.13.0-39-generic (org.apache.zookeeper.ZooKeeper)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:user.name=hdmaster (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:48,916] INFO Cluster ID = ABAJ2by9SwOaiCpX7i1YSw (kafka.server.KafkaServer)
[35mzoo2               |[0m 2018-04-27 08:52:34,968 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:user.home=/opt/bd (org.apache.zookeeper.ZooKeeper)
[31;1mkafka2             |[0m [2018-04-27 08:52:46,718] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[35mzoo2               |[0m 2018-04-27 08:52:48,502 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /172.28.0.16:44454
[31;1mkafka2             |[0m [2018-04-27 08:52:46,719] INFO Initiating client connection, connectString=zoo1:2181,zoo2:2181,zoo3:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3e92efc3 (org.apache.zookeeper.ZooKeeper)
[35;1mkafka1             |[0m [2018-04-27 08:52:48,922] WARN No meta.properties file under dir /var/log/kafka/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,408] INFO Cluster ID = A6a64bw4QhilG6g4mT-_Pw (kafka.server.KafkaServer)
[36mzoo3               |[0m 2018-04-27 08:52:33,419 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[31;1mkafka2             |[0m [2018-04-27 08:52:46,730] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[32mnamenode           |[0m 2018-04-27 08:52:35,767 INFO namenode.FSDirectory: XAttrs enabled? true
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,382 INFO datanode.DataNode: dnUserName = hdmaster
[36mzoo3               |[0m 2018-04-27 08:52:46,735 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /172.28.0.15:43204
[33mzoo1               |[0m 2018-04-27 08:52:48,588 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd49b0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
[31;1mkafka2             |[0m [2018-04-27 08:52:46,730] INFO Opening socket connection to server zoo3.kafka_kafkaNet/172.28.0.13:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[35mzoo2               |[0m 2018-04-27 08:52:48,509 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@942] - Client attempting to establish new session at /172.28.0.16:44454
[34;1mkafka3             |[0m [2018-04-27 08:52:51,484] WARN No meta.properties file under dir /var/log/kafka/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[35;1mkafka1             |[0m [2018-04-27 08:52:48,997] INFO KafkaConfig values: 
[35;1mkafka1             |[0m 	advertised.host.name = null
[35;1mkafka1             |[0m 	advertised.listeners = null
[35;1mkafka1             |[0m 	advertised.port = null
[35;1mkafka1             |[0m 	alter.config.policy.class.name = null
[35;1mkafka1             |[0m 	alter.log.dirs.replication.quota.window.num = 11
[35;1mkafka1             |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[35;1mkafka1             |[0m 	authorizer.class.name = 
[35;1mkafka1             |[0m 	auto.create.topics.enable = true
[35;1mkafka1             |[0m 	auto.leader.rebalance.enable = true
[35;1mkafka1             |[0m 	background.threads = 10
[35;1mkafka1             |[0m 	broker.id = 0
[35;1mkafka1             |[0m 	broker.id.generation.enable = true
[35;1mkafka1             |[0m 	broker.rack = null
[35;1mkafka1             |[0m 	compression.type = producer
[35;1mkafka1             |[0m 	connections.max.idle.ms = 600000
[35;1mkafka1             |[0m 	controlled.shutdown.enable = true
[35;1mkafka1             |[0m 	controlled.shutdown.max.retries = 3
[35;1mkafka1             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[35;1mkafka1             |[0m 	controller.socket.timeout.ms = 30000
[35;1mkafka1             |[0m 	create.topic.policy.class.name = null
[35;1mkafka1             |[0m 	default.replication.factor = 1
[35;1mkafka1             |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[35;1mkafka1             |[0m 	delegation.token.expiry.time.ms = 86400000
[35;1mkafka1             |[0m 	delegation.token.master.key = null
[35;1mkafka1             |[0m 	delegation.token.max.lifetime.ms = 604800000
[35;1mkafka1             |[0m 	delete.records.purgatory.purge.interval.requests = 1
[35;1mkafka1             |[0m 	delete.topic.enable = true
[35;1mkafka1             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[35;1mkafka1             |[0m 	group.initial.rebalance.delay.ms = 0
[35;1mkafka1             |[0m 	group.max.session.timeout.ms = 300000
[35;1mkafka1             |[0m 	group.min.session.timeout.ms = 6000
[35;1mkafka1             |[0m 	host.name = 
[35;1mkafka1             |[0m 	inter.broker.listener.name = null
[35;1mkafka1             |[0m 	inter.broker.protocol.version = 1.1-IV0
[35;1mkafka1             |[0m 	leader.imbalance.check.interval.seconds = 300
[35;1mkafka1             |[0m 	leader.imbalance.per.broker.percentage = 10
[35;1mkafka1             |[0m 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
[35;1mkafka1             |[0m 	listeners = null
[35;1mkafka1             |[0m 	log.cleaner.backoff.ms = 15000
[35;1mkafka1             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[35;1mkafka1             |[0m 	log.cleaner.delete.retention.ms = 86400000
[35;1mkafka1             |[0m 	log.cleaner.enable = true
[35;1mkafka1             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[35;1mkafka1             |[0m 	log.cleaner.io.buffer.size = 524288
[35;1mkafka1             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[35;1mkafka1             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[35;1mkafka1             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[35;1mkafka1             |[0m 	log.cleaner.threads = 1
[35;1mkafka1             |[0m 	log.cleanup.policy = [delete]
[35;1mkafka1             |[0m 	log.dir = /tmp/kafka-logs
[35;1mkafka1             |[0m 	log.dirs = /var/log/kafka/
[35;1mkafka1             |[0m 	log.flush.interval.messages = 9223372036854775807
[35;1mkafka1             |[0m 	log.flush.interval.ms = null
[35;1mkafka1             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[35;1mkafka1             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[35;1mkafka1             |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[35;1mkafka1             |[0m 	log.index.interval.bytes = 4096
[35;1mkafka1             |[0m 	log.index.size.max.bytes = 10485760
[35;1mkafka1             |[0m 	log.message.format.version = 1.1-IV0
[35;1mkafka1             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[35;1mkafka1             |[0m 	log.message.timestamp.type = CreateTime
[35;1mkafka1             |[0m 	log.preallocate = false
[35;1mkafka1             |[0m 	log.retention.bytes = -1
[35;1mkafka1             |[0m 	log.retention.check.interval.ms = 300000
[35;1mkafka1             |[0m 	log.retention.hours = 168
[35;1mkafka1             |[0m 	log.retention.minutes = null
[35;1mkafka1             |[0m 	log.retention.ms = null
[35;1mkafka1             |[0m 	log.roll.hours = 168
[35;1mkafka1             |[0m 	log.roll.jitter.hours = 0
[35;1mkafka1             |[0m 	log.roll.jitter.ms = null
[35;1mkafka1             |[0m 	log.roll.ms = null
[35;1mkafka1             |[0m 	log.segment.bytes = 1073741824
[35;1mkafka1             |[0m 	log.segment.delete.delay.ms = 60000
[35;1mkafka1             |[0m 	max.connections.per.ip = 2147483647
[35;1mkafka1             |[0m 	max.connections.per.ip.overrides = 
[35;1mkafka1             |[0m 	max.incremental.fetch.session.cache.slots = 1000
[35;1mkafka1             |[0m 	message.max.bytes = 1000012
[35;1mkafka1             |[0m 	metric.reporters = []
[35;1mkafka1             |[0m 	metrics.num.samples = 2
[35;1mkafka1             |[0m 	metrics.recording.level = INFO
[35;1mkafka1             |[0m 	metrics.sample.window.ms = 30000
[35;1mkafka1             |[0m 	min.insync.replicas = 1
[35;1mkafka1             |[0m 	num.io.threads = 8
[35;1mkafka1             |[0m 	num.network.threads = 3
[35;1mkafka1             |[0m 	num.partitions = 1
[35;1mkafka1             |[0m 	num.recovery.threads.per.data.dir = 1
[35;1mkafka1             |[0m 	num.replica.alter.log.dirs.threads = null
[35;1mkafka1             |[0m 	num.replica.fetchers = 1
[35;1mkafka1             |[0m 	offset.metadata.max.bytes = 4096
[35;1mkafka1             |[0m 	offsets.commit.required.acks = -1
[35;1mkafka1             |[0m 	offsets.commit.timeout.ms = 5000
[35;1mkafka1             |[0m 	offsets.load.buffer.size = 5242880
[35;1mkafka1             |[0m 	offsets.retention.check.interval.ms = 600000
[35;1mkafka1             |[0m 	offsets.retention.minutes = 1440
[35;1mkafka1             |[0m 	offsets.topic.compression.codec = 0
[35;1mkafka1             |[0m 	offsets.topic.num.partitions = 50
[35;1mkafka1             |[0m 	offsets.topic.replication.factor = 1
[35;1mkafka1             |[0m 	offsets.topic.segment.bytes = 104857600
[35;1mkafka1             |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[35;1mkafka1             |[0m 	password.encoder.iterations = 4096
[35;1mkafka1             |[0m 	password.encoder.key.length = 128
[35;1mkafka1             |[0m 	password.encoder.keyfactory.algorithm = null
[35;1mkafka1             |[0m 	password.encoder.old.secret = null
[35;1mkafka1             |[0m 	password.encoder.secret = null
[35;1mkafka1             |[0m 	port = 9092
[35;1mkafka1             |[0m 	principal.builder.class = null
[35;1mkafka1             |[0m 	producer.purgatory.purge.interval.requests = 1000
[35;1mkafka1             |[0m 	queued.max.request.bytes = -1
[35;1mkafka1             |[0m 	queued.max.requests = 500
[35;1mkafka1             |[0m 	quota.consumer.default = 9223372036854775807
[35;1mkafka1             |[0m 	quota.producer.default = 9223372036854775807
[35;1mkafka1             |[0m 	quota.window.num = 11
[35;1mkafka1             |[0m 	quota.window.size.seconds = 1
[35;1mkafka1             |[0m 	replica.fetch.backoff.ms = 1000
[35;1mkafka1             |[0m 	replica.fetch.max.bytes = 1048576
[35;1mkafka1             |[0m 	replica.fetch.min.bytes = 1
[35;1mkafka1             |[0m 	replica.fetch.response.max.bytes = 10485760
[35;1mkafka1             |[0m 	replica.fetch.wait.max.ms = 500
[35;1mkafka1             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[35;1mkafka1             |[0m 	replica.lag.time.max.ms = 10000
[35;1mkafka1             |[0m 	replica.socket.receive.buffer.bytes = 65536
[35;1mkafka1             |[0m 	replica.socket.timeout.ms = 30000
[35;1mkafka1             |[0m 	replication.quota.window.num = 11
[35;1mkafka1             |[0m 	replication.quota.window.size.seconds = 1
[35;1mkafka1             |[0m 	request.timeout.ms = 30000
[35;1mkafka1             |[0m 	reserved.broker.max.id = 1000
[35;1mkafka1             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[35;1mkafka1             |[0m 	sasl.jaas.config = null
[35;1mkafka1             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[35mzoo2               |[0m 2018-04-27 08:52:48,511 [myid:] - INFO  [SyncThread:0:FileTxnLog@203] - Creating new log file: log.1
[33mzoo1               |[0m 2018-04-27 08:52:49,987 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd49b0000 type:setData cxid:0x22 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
[34;1mkafka3             |[0m [2018-04-27 08:52:51,556] INFO KafkaConfig values: 
[36mzoo3               |[0m 2018-04-27 08:52:46,742 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@942] - Client attempting to establish new session at /172.28.0.15:43204
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,382 INFO datanode.DataNode: supergroup = supergroup
[31;1mkafka2             |[0m [2018-04-27 08:52:46,734] INFO Socket connection established to zoo3.kafka_kafkaNet/172.28.0.13:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[32mnamenode           |[0m 2018-04-27 08:52:35,768 INFO namenode.NameNode: Caching file names occurring more than 10 times
[35;1mkafka1             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[35mzoo2               |[0m 2018-04-27 08:52:48,743 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@687] - Established session 0x163064dd8230000 with negotiated timeout 6000 for client /172.28.0.16:44454
[34;1mkafka3             |[0m 	advertised.host.name = null
[33mzoo1               |[0m 2018-04-27 08:52:50,423 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd49b0000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[36mzoo3               |[0m 2018-04-27 08:52:46,743 [myid:] - INFO  [SyncThread:0:FileTxnLog@203] - Creating new log file: log.1
[31;1mkafka2             |[0m [2018-04-27 08:52:46,946] INFO Session establishment complete on server zoo3.kafka_kafkaNet/172.28.0.13:2181, sessionid = 0x163064dd2150000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,454 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
[35;1mkafka1             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[34;1mkafka3             |[0m 	advertised.listeners = null
[32mnamenode           |[0m 2018-04-27 08:52:35,771 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
[35mzoo2               |[0m 2018-04-27 08:52:48,837 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd8230000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
[35;1mkafka1             |[0m 	sasl.kerberos.service.name = null
[34;1mkafka3             |[0m 	advertised.port = null
[36mzoo3               |[0m 2018-04-27 08:52:46,945 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@687] - Established session 0x163064dd2150000 with negotiated timeout 6000 for client /172.28.0.15:43204
[31;1mkafka2             |[0m [2018-04-27 08:52:46,949] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,464 INFO ipc.Server: Starting Socket Reader #1 for port 9867
[32mnamenode           |[0m 2018-04-27 08:52:35,773 INFO snapshot.SnapshotManager: SkipList is disabled
[35;1mkafka1             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka3             |[0m 	alter.config.policy.class.name = null
[35mzoo2               |[0m 2018-04-27 08:52:49,281 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd8230000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
[36mzoo3               |[0m 2018-04-27 08:52:47,047 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd2150000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
[31;1mkafka2             |[0m [2018-04-27 08:52:49,946] INFO Cluster ID = _U1_YhmPRDiBE6qNmPxgjw (kafka.server.KafkaServer)
[35;1mkafka1             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,491 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867
[34;1mkafka3             |[0m 	alter.log.dirs.replication.quota.window.num = 11
[32mnamenode           |[0m 2018-04-27 08:52:35,776 INFO util.GSet: Computing capacity for map cachedBlocks
[36mzoo3               |[0m 2018-04-27 08:52:47,333 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd2150000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
[35mzoo2               |[0m 2018-04-27 08:52:49,587 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd8230000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
[35;1mkafka1             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[31;1mkafka2             |[0m [2018-04-27 08:52:49,951] WARN No meta.properties file under dir /var/log/kafka/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[34;1mkafka3             |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,504 INFO datanode.DataNode: Refresh request received for nameservices: null
[32mnamenode           |[0m 2018-04-27 08:52:35,776 INFO util.GSet: VM type       = 64-bit
[35;1mkafka1             |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mzoo3               |[0m 2018-04-27 08:52:47,907 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd2150000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
[35mzoo2               |[0m 2018-04-27 08:52:50,649 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd8230000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
[34;1mkafka3             |[0m 	authorizer.class.name = 
[31;1mkafka2             |[0m [2018-04-27 08:52:50,022] INFO KafkaConfig values: 
[35;1mkafka1             |[0m 	socket.receive.buffer.bytes = 102400
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,510 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>
[34;1mkafka3             |[0m 	auto.create.topics.enable = true
[36mzoo3               |[0m 2018-04-27 08:52:49,510 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd2150000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
[31;1mkafka2             |[0m 	advertised.host.name = null
[32mnamenode           |[0m 2018-04-27 08:52:35,776 INFO util.GSet: 0.25% max memory 3.6 GB = 9.1 MB
[35mzoo2               |[0m 2018-04-27 08:52:52,675 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd8230000 type:setData cxid:0x21 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
[35;1mkafka1             |[0m 	socket.request.max.bytes = 104857600
[34;1mkafka3             |[0m 	auto.leader.rebalance.enable = true
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,520 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to namenode/172.28.0.2:9000 starting to offer service
[31;1mkafka2             |[0m 	advertised.listeners = null
[32mnamenode           |[0m 2018-04-27 08:52:35,776 INFO util.GSet: capacity      = 2^20 = 1048576 entries
[36mzoo3               |[0m 2018-04-27 08:52:51,902 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd2150000 type:setData cxid:0x21 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
[35;1mkafka1             |[0m 	socket.send.buffer.bytes = 102400
[34;1mkafka3             |[0m 	background.threads = 10
[35mzoo2               |[0m 2018-04-27 08:52:53,089 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd8230000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[31;1mkafka2             |[0m 	advertised.port = null
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,525 INFO ipc.Server: IPC Server Responder: starting
[35;1mkafka1             |[0m 	ssl.cipher.suites = []
[32mnamenode           |[0m 2018-04-27 08:52:35,783 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
[34;1mkafka3             |[0m 	broker.id = 0
[36mzoo3               |[0m 2018-04-27 08:52:52,331 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@648] - Got user-level KeeperException when processing sessionid:0x163064dd2150000 type:delete cxid:0x37 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[31;1mkafka2             |[0m 	alter.config.policy.class.name = null
[33;1mdatanode2          |[0m 2018-04-27 08:52:44,525 INFO ipc.Server: IPC Server listener on 9867: starting
[35;1mkafka1             |[0m 	ssl.client.auth = none
[32mnamenode           |[0m 2018-04-27 08:52:35,783 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
[34;1mkafka3             |[0m 	broker.id.generation.enable = true
[31;1mkafka2             |[0m 	alter.log.dirs.replication.quota.window.num = 11
[35;1mkafka1             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[33;1mdatanode2          |[0m 2018-04-27 08:52:48,646 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m 	broker.rack = null
[32mnamenode           |[0m 2018-04-27 08:52:35,783 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
[31;1mkafka2             |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[35;1mkafka1             |[0m 	ssl.endpoint.identification.algorithm = null
[34;1mkafka3             |[0m 	compression.type = producer
[33;1mdatanode2          |[0m 2018-04-27 08:52:51,717 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[31;1mkafka2             |[0m 	authorizer.class.name = 
[32mnamenode           |[0m 2018-04-27 08:52:35,785 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
[35;1mkafka1             |[0m 	ssl.key.password = null
[34;1mkafka3             |[0m 	connections.max.idle.ms = 600000
[31;1mkafka2             |[0m 	auto.create.topics.enable = true
[32mnamenode           |[0m 2018-04-27 08:52:35,785 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
[35;1mkafka1             |[0m 	ssl.keymanager.algorithm = SunX509
[34;1mkafka3             |[0m 	controlled.shutdown.enable = true
[31;1mkafka2             |[0m 	auto.leader.rebalance.enable = true
[32mnamenode           |[0m 2018-04-27 08:52:35,787 INFO util.GSet: Computing capacity for map NameNodeRetryCache
[35;1mkafka1             |[0m 	ssl.keystore.location = null
[34;1mkafka3             |[0m 	controlled.shutdown.max.retries = 3
[31;1mkafka2             |[0m 	background.threads = 10
[35;1mkafka1             |[0m 	ssl.keystore.password = null
[32mnamenode           |[0m 2018-04-27 08:52:35,787 INFO util.GSet: VM type       = 64-bit
[34;1mkafka3             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[31;1mkafka2             |[0m 	broker.id = 1
[35;1mkafka1             |[0m 	ssl.keystore.type = JKS
[32mnamenode           |[0m 2018-04-27 08:52:35,787 INFO util.GSet: 0.029999999329447746% max memory 3.6 GB = 1.1 MB
[34;1mkafka3             |[0m 	controller.socket.timeout.ms = 30000
[31;1mkafka2             |[0m 	broker.id.generation.enable = true
[35;1mkafka1             |[0m 	ssl.protocol = TLS
[32mnamenode           |[0m 2018-04-27 08:52:35,787 INFO util.GSet: capacity      = 2^17 = 131072 entries
[34;1mkafka3             |[0m 	create.topic.policy.class.name = null
[31;1mkafka2             |[0m 	broker.rack = null
[35;1mkafka1             |[0m 	ssl.provider = null
[34;1mkafka3             |[0m 	default.replication.factor = 1
[31;1mkafka2             |[0m 	compression.type = producer
[35;1mkafka1             |[0m 	ssl.secure.random.implementation = null
[32mnamenode           |[0m 2018-04-27 08:52:35,988 INFO common.Storage: Lock on /var/data/hadoop/hdfs/nn/in_use.lock acquired by nodename 71@namenode
[34;1mkafka3             |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[31;1mkafka2             |[0m 	connections.max.idle.ms = 600000
[35;1mkafka1             |[0m 	ssl.trustmanager.algorithm = PKIX
[34;1mkafka3             |[0m 	delegation.token.expiry.time.ms = 86400000
[32mnamenode           |[0m 2018-04-27 08:52:35,990 WARN namenode.FSNamesystem: Encountered exception loading fsimage
[31;1mkafka2             |[0m 	controlled.shutdown.enable = true
[35;1mkafka1             |[0m 	ssl.truststore.location = null
[34;1mkafka3             |[0m 	delegation.token.master.key = null
[32mnamenode           |[0m java.io.IOException: NameNode is not formatted.
[31;1mkafka2             |[0m 	controlled.shutdown.max.retries = 3
[35;1mkafka1             |[0m 	ssl.truststore.password = null
[34;1mkafka3             |[0m 	delegation.token.max.lifetime.ms = 604800000
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:237)
[31;1mkafka2             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[35;1mkafka1             |[0m 	ssl.truststore.type = JKS
[34;1mkafka3             |[0m 	delete.records.purgatory.purge.interval.requests = 1
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1086)
[31;1mkafka2             |[0m 	controller.socket.timeout.ms = 30000
[35;1mkafka1             |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[34;1mkafka3             |[0m 	delete.topic.enable = true
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:714)
[31;1mkafka2             |[0m 	create.topic.policy.class.name = null
[35;1mkafka1             |[0m 	transaction.max.timeout.ms = 900000
[34;1mkafka3             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:669)
[31;1mkafka2             |[0m 	default.replication.factor = 1
[35;1mkafka1             |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[34;1mkafka3             |[0m 	group.initial.rebalance.delay.ms = 0
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:731)
[31;1mkafka2             |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[35;1mkafka1             |[0m 	transaction.state.log.load.buffer.size = 5242880
[34;1mkafka3             |[0m 	group.max.session.timeout.ms = 300000
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:968)
[31;1mkafka2             |[0m 	delegation.token.expiry.time.ms = 86400000
[35;1mkafka1             |[0m 	transaction.state.log.min.isr = 1
[34;1mkafka3             |[0m 	group.min.session.timeout.ms = 6000
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:947)
[31;1mkafka2             |[0m 	delegation.token.master.key = null
[35;1mkafka1             |[0m 	transaction.state.log.num.partitions = 50
[34;1mkafka3             |[0m 	host.name = 
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1674)
[31;1mkafka2             |[0m 	delegation.token.max.lifetime.ms = 604800000
[35;1mkafka1             |[0m 	transaction.state.log.replication.factor = 1
[34;1mkafka3             |[0m 	inter.broker.listener.name = null
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1741)
[31;1mkafka2             |[0m 	delete.records.purgatory.purge.interval.requests = 1
[35;1mkafka1             |[0m 	transaction.state.log.segment.bytes = 104857600
[34;1mkafka3             |[0m 	inter.broker.protocol.version = 1.1-IV0
[31;1mkafka2             |[0m 	delete.topic.enable = true
[35;1mkafka1             |[0m 	transactional.id.expiration.ms = 604800000
[32mnamenode           |[0m 2018-04-27 08:52:35,993 INFO handler.ContextHandler: Stopped o.e.j.w.WebAppContext@19b843ba{/,null,UNAVAILABLE}{/hdfs}
[34;1mkafka3             |[0m 	leader.imbalance.check.interval.seconds = 300
[31;1mkafka2             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[35;1mkafka1             |[0m 	unclean.leader.election.enable = false
[34;1mkafka3             |[0m 	leader.imbalance.per.broker.percentage = 10
[32mnamenode           |[0m 2018-04-27 08:52:35,996 INFO server.AbstractConnector: Stopped ServerConnector@2f666ebb{HTTP/1.1,[http/1.1]}{namenode:50070}
[31;1mkafka2             |[0m 	group.initial.rebalance.delay.ms = 0
[35;1mkafka1             |[0m 	zookeeper.connect = zoo1:2181,zoo2:2181,zoo3:2181
[34;1mkafka3             |[0m 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
[31;1mkafka2             |[0m 	group.max.session.timeout.ms = 300000
[35;1mkafka1             |[0m 	zookeeper.connection.timeout.ms = 6000
[32mnamenode           |[0m 2018-04-27 08:52:35,996 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@52f27fbd{/static,file:///opt/bd/hadoop-3.1.0/share/hadoop/hdfs/webapps/static/,UNAVAILABLE}
[34;1mkafka3             |[0m 	listeners = null
[31;1mkafka2             |[0m 	group.min.session.timeout.ms = 6000
[35;1mkafka1             |[0m 	zookeeper.max.in.flight.requests = 10
[34;1mkafka3             |[0m 	log.cleaner.backoff.ms = 15000
[32mnamenode           |[0m 2018-04-27 08:52:35,997 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@28dcca0c{/logs,file:///var/log/hadoop/hdfs/,UNAVAILABLE}
[31;1mkafka2             |[0m 	host.name = 
[35;1mkafka1             |[0m 	zookeeper.session.timeout.ms = 6000
[34;1mkafka3             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[32mnamenode           |[0m 2018-04-27 08:52:35,998 INFO impl.MetricsSystemImpl: Stopping NameNode metrics system...
[31;1mkafka2             |[0m 	inter.broker.listener.name = null
[35;1mkafka1             |[0m 	zookeeper.set.acl = false
[34;1mkafka3             |[0m 	log.cleaner.delete.retention.ms = 86400000
[31;1mkafka2             |[0m 	inter.broker.protocol.version = 1.1-IV0
[35;1mkafka1             |[0m 	zookeeper.sync.time.ms = 2000
[32mnamenode           |[0m 2018-04-27 08:52:35,998 INFO impl.MetricsSystemImpl: NameNode metrics system stopped.
[34;1mkafka3             |[0m 	log.cleaner.enable = true
[31;1mkafka2             |[0m 	leader.imbalance.check.interval.seconds = 300
[35;1mkafka1             |[0m  (kafka.server.KafkaConfig)
[34;1mkafka3             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[31;1mkafka2             |[0m 	leader.imbalance.per.broker.percentage = 10
[32mnamenode           |[0m 2018-04-27 08:52:35,998 INFO impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
[34;1mkafka3             |[0m 	log.cleaner.io.buffer.size = 524288
[31;1mkafka2             |[0m 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
[35;1mkafka1             |[0m [2018-04-27 08:52:49,007] INFO KafkaConfig values: 
[34;1mkafka3             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[32mnamenode           |[0m 2018-04-27 08:52:35,999 ERROR namenode.NameNode: Failed to start namenode.
[31;1mkafka2             |[0m 	listeners = null
[35;1mkafka1             |[0m 	advertised.host.name = null
[34;1mkafka3             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[32mnamenode           |[0m java.io.IOException: NameNode is not formatted.
[31;1mkafka2             |[0m 	log.cleaner.backoff.ms = 15000
[35;1mkafka1             |[0m 	advertised.listeners = null
[34;1mkafka3             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:237)
[31;1mkafka2             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[35;1mkafka1             |[0m 	advertised.port = null
[34;1mkafka3             |[0m 	log.cleaner.threads = 1
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1086)
[31;1mkafka2             |[0m 	log.cleaner.delete.retention.ms = 86400000
[35;1mkafka1             |[0m 	alter.config.policy.class.name = null
[34;1mkafka3             |[0m 	log.cleanup.policy = [delete]
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:714)
[31;1mkafka2             |[0m 	log.cleaner.enable = true
[35;1mkafka1             |[0m 	alter.log.dirs.replication.quota.window.num = 11
[34;1mkafka3             |[0m 	log.dir = /tmp/kafka-logs
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:669)
[31;1mkafka2             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[35;1mkafka1             |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[34;1mkafka3             |[0m 	log.dirs = /var/log/kafka/
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:731)
[31;1mkafka2             |[0m 	log.cleaner.io.buffer.size = 524288
[35;1mkafka1             |[0m 	authorizer.class.name = 
[34;1mkafka3             |[0m 	log.flush.interval.messages = 9223372036854775807
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:968)
[31;1mkafka2             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[35;1mkafka1             |[0m 	auto.create.topics.enable = true
[34;1mkafka3             |[0m 	log.flush.interval.ms = null
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:947)
[31;1mkafka2             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[35;1mkafka1             |[0m 	auto.leader.rebalance.enable = true
[34;1mkafka3             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1674)
[31;1mkafka2             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[35;1mkafka1             |[0m 	background.threads = 10
[34;1mkafka3             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[32mnamenode           |[0m 	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1741)
[31;1mkafka2             |[0m 	log.cleaner.threads = 1
[35;1mkafka1             |[0m 	broker.id = 0
[34;1mkafka3             |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[31;1mkafka2             |[0m 	log.cleanup.policy = [delete]
[35;1mkafka1             |[0m 	broker.id.generation.enable = true
[32mnamenode           |[0m 2018-04-27 08:52:36,000 INFO util.ExitUtil: Exiting with status 1: java.io.IOException: NameNode is not formatted.
[34;1mkafka3             |[0m 	log.index.interval.bytes = 4096
[31;1mkafka2             |[0m 	log.dir = /tmp/kafka-logs
[35;1mkafka1             |[0m 	broker.rack = null
[34;1mkafka3             |[0m 	log.index.size.max.bytes = 10485760
[31;1mkafka2             |[0m 	log.dirs = /var/log/kafka/
[32mnamenode           |[0m 2018-04-27 08:52:36,001 INFO namenode.NameNode: SHUTDOWN_MSG: 
[35;1mkafka1             |[0m 	compression.type = producer
[34;1mkafka3             |[0m 	log.message.format.version = 1.1-IV0
[31;1mkafka2             |[0m 	log.flush.interval.messages = 9223372036854775807
[32mnamenode           |[0m /************************************************************
[35;1mkafka1             |[0m 	connections.max.idle.ms = 600000
[34;1mkafka3             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[31;1mkafka2             |[0m 	log.flush.interval.ms = null
[32mnamenode           |[0m SHUTDOWN_MSG: Shutting down NameNode at namenode/172.28.0.2
[35;1mkafka1             |[0m 	controlled.shutdown.enable = true
[34;1mkafka3             |[0m 	log.message.timestamp.type = CreateTime
[31;1mkafka2             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[32mnamenode           |[0m ************************************************************/
[35;1mkafka1             |[0m 	controlled.shutdown.max.retries = 3
[34;1mkafka3             |[0m 	log.preallocate = false
[31;1mkafka2             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[35;1mkafka1             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[34;1mkafka3             |[0m 	log.retention.bytes = -1
[31;1mkafka2             |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[35;1mkafka1             |[0m 	controller.socket.timeout.ms = 30000
[34;1mkafka3             |[0m 	log.retention.check.interval.ms = 300000
[31;1mkafka2             |[0m 	log.index.interval.bytes = 4096
[35;1mkafka1             |[0m 	create.topic.policy.class.name = null
[34;1mkafka3             |[0m 	log.retention.hours = 168
[31;1mkafka2             |[0m 	log.index.size.max.bytes = 10485760
[35;1mkafka1             |[0m 	default.replication.factor = 1
[32mnamenode exited with code 1
[0m[34;1mkafka3             |[0m 	log.retention.minutes = null
[31;1mkafka2             |[0m 	log.message.format.version = 1.1-IV0
[35;1mkafka1             |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[34;1mkafka3             |[0m 	log.retention.ms = null
[31;1mkafka2             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[35;1mkafka1             |[0m 	delegation.token.expiry.time.ms = 86400000
[34;1mkafka3             |[0m 	log.roll.hours = 168
[31;1mkafka2             |[0m 	log.message.timestamp.type = CreateTime
[35;1mkafka1             |[0m 	delegation.token.master.key = null
[34;1mkafka3             |[0m 	log.roll.jitter.hours = 0
[31;1mkafka2             |[0m 	log.preallocate = false
[35;1mkafka1             |[0m 	delegation.token.max.lifetime.ms = 604800000
[34;1mkafka3             |[0m 	log.roll.jitter.ms = null
[31;1mkafka2             |[0m 	log.retention.bytes = -1
[35;1mkafka1             |[0m 	delete.records.purgatory.purge.interval.requests = 1
[34;1mkafka3             |[0m 	log.roll.ms = null
[31;1mkafka2             |[0m 	log.retention.check.interval.ms = 300000
[35;1mkafka1             |[0m 	delete.topic.enable = true
[34;1mkafka3             |[0m 	log.segment.bytes = 1073741824
[31;1mkafka2             |[0m 	log.retention.hours = 168
[35;1mkafka1             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[34;1mkafka3             |[0m 	log.segment.delete.delay.ms = 60000
[31;1mkafka2             |[0m 	log.retention.minutes = null
[35;1mkafka1             |[0m 	group.initial.rebalance.delay.ms = 0
[34;1mkafka3             |[0m 	max.connections.per.ip = 2147483647
[31;1mkafka2             |[0m 	log.retention.ms = null
[35;1mkafka1             |[0m 	group.max.session.timeout.ms = 300000
[34;1mkafka3             |[0m 	max.connections.per.ip.overrides = 
[31;1mkafka2             |[0m 	log.roll.hours = 168
[35;1mkafka1             |[0m 	group.min.session.timeout.ms = 6000
[34;1mkafka3             |[0m 	max.incremental.fetch.session.cache.slots = 1000
[31;1mkafka2             |[0m 	log.roll.jitter.hours = 0
[35;1mkafka1             |[0m 	host.name = 
[34;1mkafka3             |[0m 	message.max.bytes = 1000012
[31;1mkafka2             |[0m 	log.roll.jitter.ms = null
[35;1mkafka1             |[0m 	inter.broker.listener.name = null
[34;1mkafka3             |[0m 	metric.reporters = []
[31;1mkafka2             |[0m 	log.roll.ms = null
[35;1mkafka1             |[0m 	inter.broker.protocol.version = 1.1-IV0
[34;1mkafka3             |[0m 	metrics.num.samples = 2
[31;1mkafka2             |[0m 	log.segment.bytes = 1073741824
[35;1mkafka1             |[0m 	leader.imbalance.check.interval.seconds = 300
[34;1mkafka3             |[0m 	metrics.recording.level = INFO
[31;1mkafka2             |[0m 	log.segment.delete.delay.ms = 60000
[35;1mkafka1             |[0m 	leader.imbalance.per.broker.percentage = 10
[34;1mkafka3             |[0m 	metrics.sample.window.ms = 30000
[31;1mkafka2             |[0m 	max.connections.per.ip = 2147483647
[35;1mkafka1             |[0m 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
[34;1mkafka3             |[0m 	min.insync.replicas = 1
[31;1mkafka2             |[0m 	max.connections.per.ip.overrides = 
[35;1mkafka1             |[0m 	listeners = null
[34;1mkafka3             |[0m 	num.io.threads = 8
[31;1mkafka2             |[0m 	max.incremental.fetch.session.cache.slots = 1000
[35;1mkafka1             |[0m 	log.cleaner.backoff.ms = 15000
[34;1mkafka3             |[0m 	num.network.threads = 3
[31;1mkafka2             |[0m 	message.max.bytes = 1000012
[35;1mkafka1             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[34;1mkafka3             |[0m 	num.partitions = 1
[31;1mkafka2             |[0m 	metric.reporters = []
[35;1mkafka1             |[0m 	log.cleaner.delete.retention.ms = 86400000
[34;1mkafka3             |[0m 	num.recovery.threads.per.data.dir = 1
[31;1mkafka2             |[0m 	metrics.num.samples = 2
[35;1mkafka1             |[0m 	log.cleaner.enable = true
[34;1mkafka3             |[0m 	num.replica.alter.log.dirs.threads = null
[31;1mkafka2             |[0m 	metrics.recording.level = INFO
[35;1mkafka1             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[34;1mkafka3             |[0m 	num.replica.fetchers = 1
[31;1mkafka2             |[0m 	metrics.sample.window.ms = 30000
[35;1mkafka1             |[0m 	log.cleaner.io.buffer.size = 524288
[34;1mkafka3             |[0m 	offset.metadata.max.bytes = 4096
[31;1mkafka2             |[0m 	min.insync.replicas = 1
[35;1mkafka1             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[34;1mkafka3             |[0m 	offsets.commit.required.acks = -1
[31;1mkafka2             |[0m 	num.io.threads = 8
[35;1mkafka1             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[34;1mkafka3             |[0m 	offsets.commit.timeout.ms = 5000
[31;1mkafka2             |[0m 	num.network.threads = 3
[35;1mkafka1             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[34;1mkafka3             |[0m 	offsets.load.buffer.size = 5242880
[31;1mkafka2             |[0m 	num.partitions = 1
[35;1mkafka1             |[0m 	log.cleaner.threads = 1
[34;1mkafka3             |[0m 	offsets.retention.check.interval.ms = 600000
[31;1mkafka2             |[0m 	num.recovery.threads.per.data.dir = 1
[35;1mkafka1             |[0m 	log.cleanup.policy = [delete]
[34;1mkafka3             |[0m 	offsets.retention.minutes = 1440
[31;1mkafka2             |[0m 	num.replica.alter.log.dirs.threads = null
[35;1mkafka1             |[0m 	log.dir = /tmp/kafka-logs
[34;1mkafka3             |[0m 	offsets.topic.compression.codec = 0
[31;1mkafka2             |[0m 	num.replica.fetchers = 1
[35;1mkafka1             |[0m 	log.dirs = /var/log/kafka/
[34;1mkafka3             |[0m 	offsets.topic.num.partitions = 50
[31;1mkafka2             |[0m 	offset.metadata.max.bytes = 4096
[35;1mkafka1             |[0m 	log.flush.interval.messages = 9223372036854775807
[34;1mkafka3             |[0m 	offsets.topic.replication.factor = 1
[31;1mkafka2             |[0m 	offsets.commit.required.acks = -1
[35;1mkafka1             |[0m 	log.flush.interval.ms = null
[34;1mkafka3             |[0m 	offsets.topic.segment.bytes = 104857600
[31;1mkafka2             |[0m 	offsets.commit.timeout.ms = 5000
[35;1mkafka1             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[34;1mkafka3             |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[31;1mkafka2             |[0m 	offsets.load.buffer.size = 5242880
[35;1mkafka1             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[34;1mkafka3             |[0m 	password.encoder.iterations = 4096
[31;1mkafka2             |[0m 	offsets.retention.check.interval.ms = 600000
[35;1mkafka1             |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[34;1mkafka3             |[0m 	password.encoder.key.length = 128
[31;1mkafka2             |[0m 	offsets.retention.minutes = 1440
[35;1mkafka1             |[0m 	log.index.interval.bytes = 4096
[34;1mkafka3             |[0m 	password.encoder.keyfactory.algorithm = null
[31;1mkafka2             |[0m 	offsets.topic.compression.codec = 0
[35;1mkafka1             |[0m 	log.index.size.max.bytes = 10485760
[34;1mkafka3             |[0m 	password.encoder.old.secret = null
[31;1mkafka2             |[0m 	offsets.topic.num.partitions = 50
[35;1mkafka1             |[0m 	log.message.format.version = 1.1-IV0
[34;1mkafka3             |[0m 	password.encoder.secret = null
[31;1mkafka2             |[0m 	offsets.topic.replication.factor = 1
[35;1mkafka1             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[34;1mkafka3             |[0m 	port = 9092
[31;1mkafka2             |[0m 	offsets.topic.segment.bytes = 104857600
[35;1mkafka1             |[0m 	log.message.timestamp.type = CreateTime
[34;1mkafka3             |[0m 	principal.builder.class = null
[31;1mkafka2             |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[35;1mkafka1             |[0m 	log.preallocate = false
[34;1mkafka3             |[0m 	producer.purgatory.purge.interval.requests = 1000
[31;1mkafka2             |[0m 	password.encoder.iterations = 4096
[35;1mkafka1             |[0m 	log.retention.bytes = -1
[34;1mkafka3             |[0m 	queued.max.request.bytes = -1
[31;1mkafka2             |[0m 	password.encoder.key.length = 128
[35;1mkafka1             |[0m 	log.retention.check.interval.ms = 300000
[34;1mkafka3             |[0m 	queued.max.requests = 500
[31;1mkafka2             |[0m 	password.encoder.keyfactory.algorithm = null
[35;1mkafka1             |[0m 	log.retention.hours = 168
[34;1mkafka3             |[0m 	quota.consumer.default = 9223372036854775807
[31;1mkafka2             |[0m 	password.encoder.old.secret = null
[35;1mkafka1             |[0m 	log.retention.minutes = null
[34;1mkafka3             |[0m 	quota.producer.default = 9223372036854775807
[31;1mkafka2             |[0m 	password.encoder.secret = null
[35;1mkafka1             |[0m 	log.retention.ms = null
[34;1mkafka3             |[0m 	quota.window.num = 11
[31;1mkafka2             |[0m 	port = 9092
[35;1mkafka1             |[0m 	log.roll.hours = 168
[34;1mkafka3             |[0m 	quota.window.size.seconds = 1
[31;1mkafka2             |[0m 	principal.builder.class = null
[35;1mkafka1             |[0m 	log.roll.jitter.hours = 0
[34;1mkafka3             |[0m 	replica.fetch.backoff.ms = 1000
[31;1mkafka2             |[0m 	producer.purgatory.purge.interval.requests = 1000
[35;1mkafka1             |[0m 	log.roll.jitter.ms = null
[34;1mkafka3             |[0m 	replica.fetch.max.bytes = 1048576
[31;1mkafka2             |[0m 	queued.max.request.bytes = -1
[35;1mkafka1             |[0m 	log.roll.ms = null
[34;1mkafka3             |[0m 	replica.fetch.min.bytes = 1
[31;1mkafka2             |[0m 	queued.max.requests = 500
[35;1mkafka1             |[0m 	log.segment.bytes = 1073741824
[34;1mkafka3             |[0m 	replica.fetch.response.max.bytes = 10485760
[31;1mkafka2             |[0m 	quota.consumer.default = 9223372036854775807
[35;1mkafka1             |[0m 	log.segment.delete.delay.ms = 60000
[34;1mkafka3             |[0m 	replica.fetch.wait.max.ms = 500
[31;1mkafka2             |[0m 	quota.producer.default = 9223372036854775807
[35;1mkafka1             |[0m 	max.connections.per.ip = 2147483647
[34;1mkafka3             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[31;1mkafka2             |[0m 	quota.window.num = 11
[35;1mkafka1             |[0m 	max.connections.per.ip.overrides = 
[34;1mkafka3             |[0m 	replica.lag.time.max.ms = 10000
[31;1mkafka2             |[0m 	quota.window.size.seconds = 1
[35;1mkafka1             |[0m 	max.incremental.fetch.session.cache.slots = 1000
[34;1mkafka3             |[0m 	replica.socket.receive.buffer.bytes = 65536
[31;1mkafka2             |[0m 	replica.fetch.backoff.ms = 1000
[35;1mkafka1             |[0m 	message.max.bytes = 1000012
[34;1mkafka3             |[0m 	replica.socket.timeout.ms = 30000
[31;1mkafka2             |[0m 	replica.fetch.max.bytes = 1048576
[35;1mkafka1             |[0m 	metric.reporters = []
[34;1mkafka3             |[0m 	replication.quota.window.num = 11
[31;1mkafka2             |[0m 	replica.fetch.min.bytes = 1
[35;1mkafka1             |[0m 	metrics.num.samples = 2
[34;1mkafka3             |[0m 	replication.quota.window.size.seconds = 1
[31;1mkafka2             |[0m 	replica.fetch.response.max.bytes = 10485760
[35;1mkafka1             |[0m 	metrics.recording.level = INFO
[34;1mkafka3             |[0m 	request.timeout.ms = 30000
[31;1mkafka2             |[0m 	replica.fetch.wait.max.ms = 500
[35;1mkafka1             |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka3             |[0m 	reserved.broker.max.id = 1000
[31;1mkafka2             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[35;1mkafka1             |[0m 	min.insync.replicas = 1
[34;1mkafka3             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[31;1mkafka2             |[0m 	replica.lag.time.max.ms = 10000
[35;1mkafka1             |[0m 	num.io.threads = 8
[34;1mkafka3             |[0m 	sasl.jaas.config = null
[31;1mkafka2             |[0m 	replica.socket.receive.buffer.bytes = 65536
[35;1mkafka1             |[0m 	num.network.threads = 3
[34;1mkafka3             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka2             |[0m 	replica.socket.timeout.ms = 30000
[35;1mkafka1             |[0m 	num.partitions = 1
[34;1mkafka3             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka2             |[0m 	replication.quota.window.num = 11
[35;1mkafka1             |[0m 	num.recovery.threads.per.data.dir = 1
[34;1mkafka3             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[31;1mkafka2             |[0m 	replication.quota.window.size.seconds = 1
[35;1mkafka1             |[0m 	num.replica.alter.log.dirs.threads = null
[34;1mkafka3             |[0m 	sasl.kerberos.service.name = null
[31;1mkafka2             |[0m 	request.timeout.ms = 30000
[35;1mkafka1             |[0m 	num.replica.fetchers = 1
[34;1mkafka3             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka2             |[0m 	reserved.broker.max.id = 1000
[35;1mkafka1             |[0m 	offset.metadata.max.bytes = 4096
[34;1mkafka3             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka2             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[35;1mkafka1             |[0m 	offsets.commit.required.acks = -1
[34;1mkafka3             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[31;1mkafka2             |[0m 	sasl.jaas.config = null
[35;1mkafka1             |[0m 	offsets.commit.timeout.ms = 5000
[34;1mkafka3             |[0m 	security.inter.broker.protocol = PLAINTEXT
[31;1mkafka2             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[35;1mkafka1             |[0m 	offsets.load.buffer.size = 5242880
[34;1mkafka3             |[0m 	socket.receive.buffer.bytes = 102400
[31;1mkafka2             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[35;1mkafka1             |[0m 	offsets.retention.check.interval.ms = 600000
[34;1mkafka3             |[0m 	socket.request.max.bytes = 104857600
[31;1mkafka2             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[35;1mkafka1             |[0m 	offsets.retention.minutes = 1440
[34;1mkafka3             |[0m 	socket.send.buffer.bytes = 102400
[31;1mkafka2             |[0m 	sasl.kerberos.service.name = null
[35;1mkafka1             |[0m 	offsets.topic.compression.codec = 0
[34;1mkafka3             |[0m 	ssl.cipher.suites = []
[31;1mkafka2             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[35;1mkafka1             |[0m 	offsets.topic.num.partitions = 50
[34;1mkafka3             |[0m 	ssl.client.auth = none
[31;1mkafka2             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[35;1mkafka1             |[0m 	offsets.topic.replication.factor = 1
[34;1mkafka3             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka2             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[35;1mkafka1             |[0m 	offsets.topic.segment.bytes = 104857600
[34;1mkafka3             |[0m 	ssl.endpoint.identification.algorithm = null
[31;1mkafka2             |[0m 	security.inter.broker.protocol = PLAINTEXT
[35;1mkafka1             |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[34;1mkafka3             |[0m 	ssl.key.password = null
[31;1mkafka2             |[0m 	socket.receive.buffer.bytes = 102400
[35;1mkafka1             |[0m 	password.encoder.iterations = 4096
[34;1mkafka3             |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka2             |[0m 	socket.request.max.bytes = 104857600
[35;1mkafka1             |[0m 	password.encoder.key.length = 128
[34;1mkafka3             |[0m 	ssl.keystore.location = null
[31;1mkafka2             |[0m 	socket.send.buffer.bytes = 102400
[35;1mkafka1             |[0m 	password.encoder.keyfactory.algorithm = null
[34;1mkafka3             |[0m 	ssl.keystore.password = null
[31;1mkafka2             |[0m 	ssl.cipher.suites = []
[35;1mkafka1             |[0m 	password.encoder.old.secret = null
[34;1mkafka3             |[0m 	ssl.keystore.type = JKS
[31;1mkafka2             |[0m 	ssl.client.auth = none
[35;1mkafka1             |[0m 	password.encoder.secret = null
[34;1mkafka3             |[0m 	ssl.protocol = TLS
[31;1mkafka2             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35;1mkafka1             |[0m 	port = 9092
[34;1mkafka3             |[0m 	ssl.provider = null
[31;1mkafka2             |[0m 	ssl.endpoint.identification.algorithm = null
[35;1mkafka1             |[0m 	principal.builder.class = null
[34;1mkafka3             |[0m 	ssl.secure.random.implementation = null
[31;1mkafka2             |[0m 	ssl.key.password = null
[35;1mkafka1             |[0m 	producer.purgatory.purge.interval.requests = 1000
[34;1mkafka3             |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka2             |[0m 	ssl.keymanager.algorithm = SunX509
[35;1mkafka1             |[0m 	queued.max.request.bytes = -1
[34;1mkafka3             |[0m 	ssl.truststore.location = null
[31;1mkafka2             |[0m 	ssl.keystore.location = null
[35;1mkafka1             |[0m 	queued.max.requests = 500
[34;1mkafka3             |[0m 	ssl.truststore.password = null
[31;1mkafka2             |[0m 	ssl.keystore.password = null
[35;1mkafka1             |[0m 	quota.consumer.default = 9223372036854775807
[34;1mkafka3             |[0m 	ssl.truststore.type = JKS
[31;1mkafka2             |[0m 	ssl.keystore.type = JKS
[35;1mkafka1             |[0m 	quota.producer.default = 9223372036854775807
[34;1mkafka3             |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[31;1mkafka2             |[0m 	ssl.protocol = TLS
[35;1mkafka1             |[0m 	quota.window.num = 11
[34;1mkafka3             |[0m 	transaction.max.timeout.ms = 900000
[31;1mkafka2             |[0m 	ssl.provider = null
[35;1mkafka1             |[0m 	quota.window.size.seconds = 1
[34;1mkafka3             |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[31;1mkafka2             |[0m 	ssl.secure.random.implementation = null
[35;1mkafka1             |[0m 	replica.fetch.backoff.ms = 1000
[34;1mkafka3             |[0m 	transaction.state.log.load.buffer.size = 5242880
[31;1mkafka2             |[0m 	ssl.trustmanager.algorithm = PKIX
[35;1mkafka1             |[0m 	replica.fetch.max.bytes = 1048576
[34;1mkafka3             |[0m 	transaction.state.log.min.isr = 1
[31;1mkafka2             |[0m 	ssl.truststore.location = null
[35;1mkafka1             |[0m 	replica.fetch.min.bytes = 1
[34;1mkafka3             |[0m 	transaction.state.log.num.partitions = 50
[31;1mkafka2             |[0m 	ssl.truststore.password = null
[35;1mkafka1             |[0m 	replica.fetch.response.max.bytes = 10485760
[34;1mkafka3             |[0m 	transaction.state.log.replication.factor = 1
[31;1mkafka2             |[0m 	ssl.truststore.type = JKS
[35;1mkafka1             |[0m 	replica.fetch.wait.max.ms = 500
[34;1mkafka3             |[0m 	transaction.state.log.segment.bytes = 104857600
[31;1mkafka2             |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[35;1mkafka1             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[34;1mkafka3             |[0m 	transactional.id.expiration.ms = 604800000
[31;1mkafka2             |[0m 	transaction.max.timeout.ms = 900000
[35;1mkafka1             |[0m 	replica.lag.time.max.ms = 10000
[34;1mkafka3             |[0m 	unclean.leader.election.enable = false
[31;1mkafka2             |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[35;1mkafka1             |[0m 	replica.socket.receive.buffer.bytes = 65536
[34;1mkafka3             |[0m 	zookeeper.connect = zoo1:2181,zoo2:2181,zoo3:2181
[31;1mkafka2             |[0m 	transaction.state.log.load.buffer.size = 5242880
[35;1mkafka1             |[0m 	replica.socket.timeout.ms = 30000
[34;1mkafka3             |[0m 	zookeeper.connection.timeout.ms = 6000
[31;1mkafka2             |[0m 	transaction.state.log.min.isr = 1
[35;1mkafka1             |[0m 	replication.quota.window.num = 11
[34;1mkafka3             |[0m 	zookeeper.max.in.flight.requests = 10
[31;1mkafka2             |[0m 	transaction.state.log.num.partitions = 50
[35;1mkafka1             |[0m 	replication.quota.window.size.seconds = 1
[34;1mkafka3             |[0m 	zookeeper.session.timeout.ms = 6000
[31;1mkafka2             |[0m 	transaction.state.log.replication.factor = 1
[35;1mkafka1             |[0m 	request.timeout.ms = 30000
[34;1mkafka3             |[0m 	zookeeper.set.acl = false
[31;1mkafka2             |[0m 	transaction.state.log.segment.bytes = 104857600
[35;1mkafka1             |[0m 	reserved.broker.max.id = 1000
[34;1mkafka3             |[0m 	zookeeper.sync.time.ms = 2000
[31;1mkafka2             |[0m 	transactional.id.expiration.ms = 604800000
[35;1mkafka1             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[34;1mkafka3             |[0m  (kafka.server.KafkaConfig)
[31;1mkafka2             |[0m 	unclean.leader.election.enable = false
[35;1mkafka1             |[0m 	sasl.jaas.config = null
[31;1mkafka2             |[0m 	zookeeper.connect = zoo1:2181,zoo2:2181,zoo3:2181
[35;1mkafka1             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka2             |[0m 	zookeeper.connection.timeout.ms = 6000
[34;1mkafka3             |[0m [2018-04-27 08:52:51,564] INFO KafkaConfig values: 
[35;1mkafka1             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[31;1mkafka2             |[0m 	zookeeper.max.in.flight.requests = 10
[31;1mkafka2             |[0m 	zookeeper.session.timeout.ms = 6000
[31;1mkafka2             |[0m 	zookeeper.set.acl = false
[31;1mkafka2             |[0m 	zookeeper.sync.time.ms = 2000
[31;1mkafka2             |[0m  (kafka.server.KafkaConfig)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,029] INFO KafkaConfig values: 
[31;1mkafka2             |[0m 	advertised.host.name = null
[31;1mkafka2             |[0m 	advertised.listeners = null
[31;1mkafka2             |[0m 	advertised.port = null
[31;1mkafka2             |[0m 	alter.config.policy.class.name = null
[31;1mkafka2             |[0m 	alter.log.dirs.replication.quota.window.num = 11
[31;1mkafka2             |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[31;1mkafka2             |[0m 	authorizer.class.name = 
[31;1mkafka2             |[0m 	auto.create.topics.enable = true
[31;1mkafka2             |[0m 	auto.leader.rebalance.enable = true
[31;1mkafka2             |[0m 	background.threads = 10
[31;1mkafka2             |[0m 	broker.id = 1
[34;1mkafka3             |[0m 	advertised.host.name = null
[34;1mkafka3             |[0m 	advertised.listeners = null
[34;1mkafka3             |[0m 	advertised.port = null
[31;1mkafka2             |[0m 	broker.id.generation.enable = true
[34;1mkafka3             |[0m 	alter.config.policy.class.name = null
[35;1mkafka1             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[31;1mkafka2             |[0m 	broker.rack = null
[34;1mkafka3             |[0m 	alter.log.dirs.replication.quota.window.num = 11
[35;1mkafka1             |[0m 	sasl.kerberos.service.name = null
[31;1mkafka2             |[0m 	compression.type = producer
[31;1mkafka2             |[0m 	connections.max.idle.ms = 600000
[31;1mkafka2             |[0m 	controlled.shutdown.enable = true
[31;1mkafka2             |[0m 	controlled.shutdown.max.retries = 3
[31;1mkafka2             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[31;1mkafka2             |[0m 	controller.socket.timeout.ms = 30000
[31;1mkafka2             |[0m 	create.topic.policy.class.name = null
[31;1mkafka2             |[0m 	default.replication.factor = 1
[31;1mkafka2             |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[31;1mkafka2             |[0m 	delegation.token.expiry.time.ms = 86400000
[31;1mkafka2             |[0m 	delegation.token.master.key = null
[31;1mkafka2             |[0m 	delegation.token.max.lifetime.ms = 604800000
[31;1mkafka2             |[0m 	delete.records.purgatory.purge.interval.requests = 1
[31;1mkafka2             |[0m 	delete.topic.enable = true
[31;1mkafka2             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[31;1mkafka2             |[0m 	group.initial.rebalance.delay.ms = 0
[31;1mkafka2             |[0m 	group.max.session.timeout.ms = 300000
[35;1mkafka1             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[34;1mkafka3             |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[34;1mkafka3             |[0m 	authorizer.class.name = 
[34;1mkafka3             |[0m 	auto.create.topics.enable = true
[34;1mkafka3             |[0m 	auto.leader.rebalance.enable = true
[34;1mkafka3             |[0m 	background.threads = 10
[34;1mkafka3             |[0m 	broker.id = 0
[34;1mkafka3             |[0m 	broker.id.generation.enable = true
[34;1mkafka3             |[0m 	broker.rack = null
[34;1mkafka3             |[0m 	compression.type = producer
[34;1mkafka3             |[0m 	connections.max.idle.ms = 600000
[34;1mkafka3             |[0m 	controlled.shutdown.enable = true
[34;1mkafka3             |[0m 	controlled.shutdown.max.retries = 3
[34;1mkafka3             |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[34;1mkafka3             |[0m 	controller.socket.timeout.ms = 30000
[34;1mkafka3             |[0m 	create.topic.policy.class.name = null
[34;1mkafka3             |[0m 	default.replication.factor = 1
[34;1mkafka3             |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[34;1mkafka3             |[0m 	delegation.token.expiry.time.ms = 86400000
[34;1mkafka3             |[0m 	delegation.token.master.key = null
[34;1mkafka3             |[0m 	delegation.token.max.lifetime.ms = 604800000
[34;1mkafka3             |[0m 	delete.records.purgatory.purge.interval.requests = 1
[34;1mkafka3             |[0m 	delete.topic.enable = true
[34;1mkafka3             |[0m 	fetch.purgatory.purge.interval.requests = 1000
[34;1mkafka3             |[0m 	group.initial.rebalance.delay.ms = 0
[34;1mkafka3             |[0m 	group.max.session.timeout.ms = 300000
[34;1mkafka3             |[0m 	group.min.session.timeout.ms = 6000
[34;1mkafka3             |[0m 	host.name = 
[34;1mkafka3             |[0m 	inter.broker.listener.name = null
[34;1mkafka3             |[0m 	inter.broker.protocol.version = 1.1-IV0
[34;1mkafka3             |[0m 	leader.imbalance.check.interval.seconds = 300
[34;1mkafka3             |[0m 	leader.imbalance.per.broker.percentage = 10
[34;1mkafka3             |[0m 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
[34;1mkafka3             |[0m 	listeners = null
[34;1mkafka3             |[0m 	log.cleaner.backoff.ms = 15000
[34;1mkafka3             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[34;1mkafka3             |[0m 	log.cleaner.delete.retention.ms = 86400000
[34;1mkafka3             |[0m 	log.cleaner.enable = true
[34;1mkafka3             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[34;1mkafka3             |[0m 	log.cleaner.io.buffer.size = 524288
[34;1mkafka3             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[34;1mkafka3             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[34;1mkafka3             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[34;1mkafka3             |[0m 	log.cleaner.threads = 1
[34;1mkafka3             |[0m 	log.cleanup.policy = [delete]
[34;1mkafka3             |[0m 	log.dir = /tmp/kafka-logs
[34;1mkafka3             |[0m 	log.dirs = /var/log/kafka/
[34;1mkafka3             |[0m 	log.flush.interval.messages = 9223372036854775807
[34;1mkafka3             |[0m 	log.flush.interval.ms = null
[34;1mkafka3             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[34;1mkafka3             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[34;1mkafka3             |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[34;1mkafka3             |[0m 	log.index.interval.bytes = 4096
[34;1mkafka3             |[0m 	log.index.size.max.bytes = 10485760
[34;1mkafka3             |[0m 	log.message.format.version = 1.1-IV0
[34;1mkafka3             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[34;1mkafka3             |[0m 	log.message.timestamp.type = CreateTime
[34;1mkafka3             |[0m 	log.preallocate = false
[34;1mkafka3             |[0m 	log.retention.bytes = -1
[34;1mkafka3             |[0m 	log.retention.check.interval.ms = 300000
[34;1mkafka3             |[0m 	log.retention.hours = 168
[34;1mkafka3             |[0m 	log.retention.minutes = null
[34;1mkafka3             |[0m 	log.retention.ms = null
[34;1mkafka3             |[0m 	log.roll.hours = 168
[34;1mkafka3             |[0m 	log.roll.jitter.hours = 0
[34;1mkafka3             |[0m 	log.roll.jitter.ms = null
[34;1mkafka3             |[0m 	log.roll.ms = null
[34;1mkafka3             |[0m 	log.segment.bytes = 1073741824
[34;1mkafka3             |[0m 	log.segment.delete.delay.ms = 60000
[34;1mkafka3             |[0m 	max.connections.per.ip = 2147483647
[31;1mkafka2             |[0m 	group.min.session.timeout.ms = 6000
[35;1mkafka1             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[34;1mkafka3             |[0m 	max.connections.per.ip.overrides = 
[31;1mkafka2             |[0m 	host.name = 
[35;1mkafka1             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[35;1mkafka1             |[0m 	security.inter.broker.protocol = PLAINTEXT
[35;1mkafka1             |[0m 	socket.receive.buffer.bytes = 102400
[35;1mkafka1             |[0m 	socket.request.max.bytes = 104857600
[35;1mkafka1             |[0m 	socket.send.buffer.bytes = 102400
[35;1mkafka1             |[0m 	ssl.cipher.suites = []
[35;1mkafka1             |[0m 	ssl.client.auth = none
[35;1mkafka1             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[35;1mkafka1             |[0m 	ssl.endpoint.identification.algorithm = null
[35;1mkafka1             |[0m 	ssl.key.password = null
[34;1mkafka3             |[0m 	max.incremental.fetch.session.cache.slots = 1000
[35;1mkafka1             |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka2             |[0m 	inter.broker.listener.name = null
[31;1mkafka2             |[0m 	inter.broker.protocol.version = 1.1-IV0
[35;1mkafka1             |[0m 	ssl.keystore.location = null
[31;1mkafka2             |[0m 	leader.imbalance.check.interval.seconds = 300
[34;1mkafka3             |[0m 	message.max.bytes = 1000012
[35;1mkafka1             |[0m 	ssl.keystore.password = null
[31;1mkafka2             |[0m 	leader.imbalance.per.broker.percentage = 10
[34;1mkafka3             |[0m 	metric.reporters = []
[35;1mkafka1             |[0m 	ssl.keystore.type = JKS
[31;1mkafka2             |[0m 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
[34;1mkafka3             |[0m 	metrics.num.samples = 2
[35;1mkafka1             |[0m 	ssl.protocol = TLS
[31;1mkafka2             |[0m 	listeners = null
[34;1mkafka3             |[0m 	metrics.recording.level = INFO
[35;1mkafka1             |[0m 	ssl.provider = null
[31;1mkafka2             |[0m 	log.cleaner.backoff.ms = 15000
[34;1mkafka3             |[0m 	metrics.sample.window.ms = 30000
[35;1mkafka1             |[0m 	ssl.secure.random.implementation = null
[31;1mkafka2             |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[34;1mkafka3             |[0m 	min.insync.replicas = 1
[35;1mkafka1             |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka2             |[0m 	log.cleaner.delete.retention.ms = 86400000
[34;1mkafka3             |[0m 	num.io.threads = 8
[35;1mkafka1             |[0m 	ssl.truststore.location = null
[31;1mkafka2             |[0m 	log.cleaner.enable = true
[34;1mkafka3             |[0m 	num.network.threads = 3
[35;1mkafka1             |[0m 	ssl.truststore.password = null
[31;1mkafka2             |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[34;1mkafka3             |[0m 	num.partitions = 1
[35;1mkafka1             |[0m 	ssl.truststore.type = JKS
[31;1mkafka2             |[0m 	log.cleaner.io.buffer.size = 524288
[34;1mkafka3             |[0m 	num.recovery.threads.per.data.dir = 1
[35;1mkafka1             |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[31;1mkafka2             |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[34;1mkafka3             |[0m 	num.replica.alter.log.dirs.threads = null
[35;1mkafka1             |[0m 	transaction.max.timeout.ms = 900000
[31;1mkafka2             |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[34;1mkafka3             |[0m 	num.replica.fetchers = 1
[35;1mkafka1             |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[31;1mkafka2             |[0m 	log.cleaner.min.compaction.lag.ms = 0
[34;1mkafka3             |[0m 	offset.metadata.max.bytes = 4096
[35;1mkafka1             |[0m 	transaction.state.log.load.buffer.size = 5242880
[31;1mkafka2             |[0m 	log.cleaner.threads = 1
[34;1mkafka3             |[0m 	offsets.commit.required.acks = -1
[35;1mkafka1             |[0m 	transaction.state.log.min.isr = 1
[31;1mkafka2             |[0m 	log.cleanup.policy = [delete]
[34;1mkafka3             |[0m 	offsets.commit.timeout.ms = 5000
[35;1mkafka1             |[0m 	transaction.state.log.num.partitions = 50
[31;1mkafka2             |[0m 	log.dir = /tmp/kafka-logs
[34;1mkafka3             |[0m 	offsets.load.buffer.size = 5242880
[35;1mkafka1             |[0m 	transaction.state.log.replication.factor = 1
[31;1mkafka2             |[0m 	log.dirs = /var/log/kafka/
[34;1mkafka3             |[0m 	offsets.retention.check.interval.ms = 600000
[35;1mkafka1             |[0m 	transaction.state.log.segment.bytes = 104857600
[31;1mkafka2             |[0m 	log.flush.interval.messages = 9223372036854775807
[34;1mkafka3             |[0m 	offsets.retention.minutes = 1440
[35;1mkafka1             |[0m 	transactional.id.expiration.ms = 604800000
[31;1mkafka2             |[0m 	log.flush.interval.ms = null
[34;1mkafka3             |[0m 	offsets.topic.compression.codec = 0
[35;1mkafka1             |[0m 	unclean.leader.election.enable = false
[31;1mkafka2             |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[34;1mkafka3             |[0m 	offsets.topic.num.partitions = 50
[35;1mkafka1             |[0m 	zookeeper.connect = zoo1:2181,zoo2:2181,zoo3:2181
[31;1mkafka2             |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[34;1mkafka3             |[0m 	offsets.topic.replication.factor = 1
[35;1mkafka1             |[0m 	zookeeper.connection.timeout.ms = 6000
[31;1mkafka2             |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[34;1mkafka3             |[0m 	offsets.topic.segment.bytes = 104857600
[35;1mkafka1             |[0m 	zookeeper.max.in.flight.requests = 10
[31;1mkafka2             |[0m 	log.index.interval.bytes = 4096
[34;1mkafka3             |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[35;1mkafka1             |[0m 	zookeeper.session.timeout.ms = 6000
[31;1mkafka2             |[0m 	log.index.size.max.bytes = 10485760
[34;1mkafka3             |[0m 	password.encoder.iterations = 4096
[35;1mkafka1             |[0m 	zookeeper.set.acl = false
[31;1mkafka2             |[0m 	log.message.format.version = 1.1-IV0
[34;1mkafka3             |[0m 	password.encoder.key.length = 128
[35;1mkafka1             |[0m 	zookeeper.sync.time.ms = 2000
[31;1mkafka2             |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[34;1mkafka3             |[0m 	password.encoder.keyfactory.algorithm = null
[35;1mkafka1             |[0m  (kafka.server.KafkaConfig)
[31;1mkafka2             |[0m 	log.message.timestamp.type = CreateTime
[34;1mkafka3             |[0m 	password.encoder.old.secret = null
[31;1mkafka2             |[0m 	log.preallocate = false
[34;1mkafka3             |[0m 	password.encoder.secret = null
[35;1mkafka1             |[0m [2018-04-27 08:52:49,029] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[31;1mkafka2             |[0m 	log.retention.bytes = -1
[34;1mkafka3             |[0m 	port = 9092
[31;1mkafka2             |[0m 	log.retention.check.interval.ms = 300000
[34;1mkafka3             |[0m 	principal.builder.class = null
[35;1mkafka1             |[0m [2018-04-27 08:52:49,029] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[31;1mkafka2             |[0m 	log.retention.hours = 168
[34;1mkafka3             |[0m 	producer.purgatory.purge.interval.requests = 1000
[31;1mkafka2             |[0m 	log.retention.minutes = null
[34;1mkafka3             |[0m 	queued.max.request.bytes = -1
[35;1mkafka1             |[0m [2018-04-27 08:52:49,030] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[31;1mkafka2             |[0m 	log.retention.ms = null
[34;1mkafka3             |[0m 	queued.max.requests = 500
[31;1mkafka2             |[0m 	log.roll.hours = 168
[35;1mkafka1             |[0m [2018-04-27 08:52:49,059] INFO Loading logs. (kafka.log.LogManager)
[34;1mkafka3             |[0m 	quota.consumer.default = 9223372036854775807
[31;1mkafka2             |[0m 	log.roll.jitter.hours = 0
[34;1mkafka3             |[0m 	quota.producer.default = 9223372036854775807
[35;1mkafka1             |[0m [2018-04-27 08:52:49,066] INFO Logs loading complete in 7 ms. (kafka.log.LogManager)
[31;1mkafka2             |[0m 	log.roll.jitter.ms = null
[34;1mkafka3             |[0m 	quota.window.num = 11
[31;1mkafka2             |[0m 	log.roll.ms = null
[35;1mkafka1             |[0m [2018-04-27 08:52:49,076] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[34;1mkafka3             |[0m 	quota.window.size.seconds = 1
[31;1mkafka2             |[0m 	log.segment.bytes = 1073741824
[34;1mkafka3             |[0m 	replica.fetch.backoff.ms = 1000
[35;1mkafka1             |[0m [2018-04-27 08:52:49,078] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[31;1mkafka2             |[0m 	log.segment.delete.delay.ms = 60000
[34;1mkafka3             |[0m 	replica.fetch.max.bytes = 1048576
[31;1mkafka2             |[0m 	max.connections.per.ip = 2147483647
[35;1mkafka1             |[0m [2018-04-27 08:52:49,321] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[34;1mkafka3             |[0m 	replica.fetch.min.bytes = 1
[31;1mkafka2             |[0m 	max.connections.per.ip.overrides = 
[34;1mkafka3             |[0m 	replica.fetch.response.max.bytes = 10485760
[31;1mkafka2             |[0m 	max.incremental.fetch.session.cache.slots = 1000
[35;1mkafka1             |[0m [2018-04-27 08:52:49,391] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[34;1mkafka3             |[0m 	replica.fetch.wait.max.ms = 500
[31;1mkafka2             |[0m 	message.max.bytes = 1000012
[34;1mkafka3             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[35;1mkafka1             |[0m [2018-04-27 08:52:49,412] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m 	metric.reporters = []
[34;1mkafka3             |[0m 	replica.lag.time.max.ms = 10000
[31;1mkafka2             |[0m 	metrics.num.samples = 2
[34;1mkafka3             |[0m 	replica.socket.receive.buffer.bytes = 65536
[35;1mkafka1             |[0m [2018-04-27 08:52:49,412] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m 	metrics.recording.level = INFO
[34;1mkafka3             |[0m 	replica.socket.timeout.ms = 30000
[31;1mkafka2             |[0m 	metrics.sample.window.ms = 30000
[34;1mkafka3             |[0m 	replication.quota.window.num = 11
[35;1mkafka1             |[0m [2018-04-27 08:52:49,417] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m 	min.insync.replicas = 1
[34;1mkafka3             |[0m 	replication.quota.window.size.seconds = 1
[31;1mkafka2             |[0m 	num.io.threads = 8
[34;1mkafka3             |[0m 	request.timeout.ms = 30000
[31;1mkafka2             |[0m 	num.network.threads = 3
[35;1mkafka1             |[0m [2018-04-27 08:52:49,426] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[34;1mkafka3             |[0m 	reserved.broker.max.id = 1000
[31;1mkafka2             |[0m 	num.partitions = 1
[34;1mkafka3             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[31;1mkafka2             |[0m 	num.recovery.threads.per.data.dir = 1
[35;1mkafka1             |[0m [2018-04-27 08:52:49,461] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m 	sasl.jaas.config = null
[31;1mkafka2             |[0m 	num.replica.alter.log.dirs.threads = null
[34;1mkafka3             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[31;1mkafka2             |[0m 	num.replica.fetchers = 1
[34;1mkafka3             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[35;1mkafka1             |[0m [2018-04-27 08:52:49,587] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[31;1mkafka2             |[0m 	offset.metadata.max.bytes = 4096
[34;1mkafka3             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[31;1mkafka2             |[0m 	offsets.commit.required.acks = -1
[34;1mkafka3             |[0m 	sasl.kerberos.service.name = null
[31;1mkafka2             |[0m 	offsets.commit.timeout.ms = 5000
[35;1mkafka1             |[0m [2018-04-27 08:52:49,589] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(kafka1,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka2             |[0m 	offsets.load.buffer.size = 5242880
[34;1mkafka3             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka2             |[0m 	offsets.retention.check.interval.ms = 600000
[35;1mkafka1             |[0m [2018-04-27 08:52:49,591] WARN No meta.properties file under dir /var/log/kafka/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[34;1mkafka3             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[31;1mkafka2             |[0m 	offsets.retention.minutes = 1440
[34;1mkafka3             |[0m 	security.inter.broker.protocol = PLAINTEXT
[31;1mkafka2             |[0m 	offsets.topic.compression.codec = 0
[34;1mkafka3             |[0m 	socket.receive.buffer.bytes = 102400
[35;1mkafka1             |[0m [2018-04-27 08:52:49,819] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m 	offsets.topic.num.partitions = 50
[34;1mkafka3             |[0m 	socket.request.max.bytes = 104857600
[31;1mkafka2             |[0m 	offsets.topic.replication.factor = 1
[34;1mkafka3             |[0m 	socket.send.buffer.bytes = 102400
[35;1mkafka1             |[0m [2018-04-27 08:52:49,820] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m 	offsets.topic.segment.bytes = 104857600
[34;1mkafka3             |[0m 	ssl.cipher.suites = []
[31;1mkafka2             |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[34;1mkafka3             |[0m 	ssl.client.auth = none
[35;1mkafka1             |[0m [2018-04-27 08:52:49,821] INFO Creating /controller (is it secure? false) (kafka.zk.KafkaZkClient)
[31;1mkafka2             |[0m 	password.encoder.iterations = 4096
[34;1mkafka3             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka2             |[0m 	password.encoder.key.length = 128
[34;1mkafka3             |[0m 	ssl.endpoint.identification.algorithm = null
[35;1mkafka1             |[0m [2018-04-27 08:52:49,821] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m 	password.encoder.keyfactory.algorithm = null
[34;1mkafka3             |[0m 	ssl.key.password = null
[31;1mkafka2             |[0m 	password.encoder.old.secret = null
[35;1mkafka1             |[0m [2018-04-27 08:52:49,947] INFO Result of znode creation at /controller is: OK (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka2             |[0m 	password.encoder.secret = null
[34;1mkafka3             |[0m 	ssl.keystore.location = null
[35;1mkafka1             |[0m [2018-04-27 08:52:49,955] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[31;1mkafka2             |[0m 	port = 9092
[34;1mkafka3             |[0m 	ssl.keystore.password = null
[31;1mkafka2             |[0m 	principal.builder.class = null
[34;1mkafka3             |[0m 	ssl.keystore.type = JKS
[35;1mkafka1             |[0m [2018-04-27 08:52:49,983] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[31;1mkafka2             |[0m 	producer.purgatory.purge.interval.requests = 1000
[34;1mkafka3             |[0m 	ssl.protocol = TLS
[31;1mkafka2             |[0m 	queued.max.request.bytes = -1
[34;1mkafka3             |[0m 	ssl.provider = null
[31;1mkafka2             |[0m 	queued.max.requests = 500
[35;1mkafka1             |[0m [2018-04-27 08:52:49,989] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[34;1mkafka3             |[0m 	ssl.secure.random.implementation = null
[31;1mkafka2             |[0m 	quota.consumer.default = 9223372036854775807
[34;1mkafka3             |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka2             |[0m 	quota.producer.default = 9223372036854775807
[34;1mkafka3             |[0m 	ssl.truststore.location = null
[35;1mkafka1             |[0m [2018-04-27 08:52:50,161] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[31;1mkafka2             |[0m 	quota.window.num = 11
[34;1mkafka3             |[0m 	ssl.truststore.password = null
[31;1mkafka2             |[0m 	quota.window.size.seconds = 1
[34;1mkafka3             |[0m 	ssl.truststore.type = JKS
[35;1mkafka1             |[0m [2018-04-27 08:52:50,272] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[31;1mkafka2             |[0m 	replica.fetch.backoff.ms = 1000
[34;1mkafka3             |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[31;1mkafka2             |[0m 	replica.fetch.max.bytes = 1048576
[35;1mkafka1             |[0m [2018-04-27 08:52:50,277] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[34;1mkafka3             |[0m 	transaction.max.timeout.ms = 900000
[31;1mkafka2             |[0m 	replica.fetch.min.bytes = 1
[34;1mkafka3             |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[31;1mkafka2             |[0m 	replica.fetch.response.max.bytes = 10485760
[35;1mkafka1             |[0m [2018-04-27 08:52:50,278] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[34;1mkafka3             |[0m 	transaction.state.log.load.buffer.size = 5242880
[31;1mkafka2             |[0m 	replica.fetch.wait.max.ms = 500
[34;1mkafka3             |[0m 	transaction.state.log.min.isr = 1
[31;1mkafka2             |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[35;1mkafka1             |[0m [2018-04-27 08:52:50,325] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[34;1mkafka3             |[0m 	transaction.state.log.num.partitions = 50
[31;1mkafka2             |[0m 	replica.lag.time.max.ms = 10000
[34;1mkafka3             |[0m 	transaction.state.log.replication.factor = 1
[31;1mkafka2             |[0m 	replica.socket.receive.buffer.bytes = 65536
[35;1mkafka1             |[0m [2018-04-27 08:52:50,340] INFO Kafka version : 1.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka3             |[0m 	transaction.state.log.segment.bytes = 104857600
[31;1mkafka2             |[0m 	replica.socket.timeout.ms = 30000
[35;1mkafka1             |[0m [2018-04-27 08:52:50,340] INFO Kafka commitId : fdcf75ea326b8e07 (org.apache.kafka.common.utils.AppInfoParser)
[34;1mkafka3             |[0m 	transactional.id.expiration.ms = 604800000
[31;1mkafka2             |[0m 	replication.quota.window.num = 11
[35;1mkafka1             |[0m [2018-04-27 08:52:50,341] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[34;1mkafka3             |[0m 	unclean.leader.election.enable = false
[31;1mkafka2             |[0m 	replication.quota.window.size.seconds = 1
[34;1mkafka3             |[0m 	zookeeper.connect = zoo1:2181,zoo2:2181,zoo3:2181
[31;1mkafka2             |[0m 	request.timeout.ms = 30000
[34;1mkafka3             |[0m 	zookeeper.connection.timeout.ms = 6000
[31;1mkafka2             |[0m 	reserved.broker.max.id = 1000
[34;1mkafka3             |[0m 	zookeeper.max.in.flight.requests = 10
[31;1mkafka2             |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[34;1mkafka3             |[0m 	zookeeper.session.timeout.ms = 6000
[31;1mkafka2             |[0m 	sasl.jaas.config = null
[34;1mkafka3             |[0m 	zookeeper.set.acl = false
[31;1mkafka2             |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[34;1mkafka3             |[0m 	zookeeper.sync.time.ms = 2000
[31;1mkafka2             |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[34;1mkafka3             |[0m  (kafka.server.KafkaConfig)
[31;1mkafka2             |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[31;1mkafka2             |[0m 	sasl.kerberos.service.name = null
[31;1mkafka2             |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[31;1mkafka2             |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[31;1mkafka2             |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[31;1mkafka2             |[0m 	security.inter.broker.protocol = PLAINTEXT
[31;1mkafka2             |[0m 	socket.receive.buffer.bytes = 102400
[31;1mkafka2             |[0m 	socket.request.max.bytes = 104857600
[31;1mkafka2             |[0m 	socket.send.buffer.bytes = 102400
[31;1mkafka2             |[0m 	ssl.cipher.suites = []
[31;1mkafka2             |[0m 	ssl.client.auth = none
[31;1mkafka2             |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[31;1mkafka2             |[0m 	ssl.endpoint.identification.algorithm = null
[31;1mkafka2             |[0m 	ssl.key.password = null
[31;1mkafka2             |[0m 	ssl.keymanager.algorithm = SunX509
[31;1mkafka2             |[0m 	ssl.keystore.location = null
[31;1mkafka2             |[0m 	ssl.keystore.password = null
[31;1mkafka2             |[0m 	ssl.keystore.type = JKS
[31;1mkafka2             |[0m 	ssl.protocol = TLS
[31;1mkafka2             |[0m 	ssl.provider = null
[31;1mkafka2             |[0m 	ssl.secure.random.implementation = null
[31;1mkafka2             |[0m 	ssl.trustmanager.algorithm = PKIX
[31;1mkafka2             |[0m 	ssl.truststore.location = null
[31;1mkafka2             |[0m 	ssl.truststore.password = null
[31;1mkafka2             |[0m 	ssl.truststore.type = JKS
[31;1mkafka2             |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[31;1mkafka2             |[0m 	transaction.max.timeout.ms = 900000
[31;1mkafka2             |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[31;1mkafka2             |[0m 	transaction.state.log.load.buffer.size = 5242880
[31;1mkafka2             |[0m 	transaction.state.log.min.isr = 1
[31;1mkafka2             |[0m 	transaction.state.log.num.partitions = 50
[31;1mkafka2             |[0m 	transaction.state.log.replication.factor = 1
[31;1mkafka2             |[0m 	transaction.state.log.segment.bytes = 104857600
[31;1mkafka2             |[0m 	transactional.id.expiration.ms = 604800000
[31;1mkafka2             |[0m 	unclean.leader.election.enable = false
[31;1mkafka2             |[0m 	zookeeper.connect = zoo1:2181,zoo2:2181,zoo3:2181
[31;1mkafka2             |[0m 	zookeeper.connection.timeout.ms = 6000
[31;1mkafka2             |[0m 	zookeeper.max.in.flight.requests = 10
[31;1mkafka2             |[0m 	zookeeper.session.timeout.ms = 6000
[31;1mkafka2             |[0m 	zookeeper.set.acl = false
[31;1mkafka2             |[0m 	zookeeper.sync.time.ms = 2000
[31;1mkafka2             |[0m  (kafka.server.KafkaConfig)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,584] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,584] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,584] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,047] INFO [ThrottledRequestReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,047] INFO [ThrottledRequestReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,611] INFO Loading logs. (kafka.log.LogManager)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,618] INFO Logs loading complete in 7 ms. (kafka.log.LogManager)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,629] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,047] INFO [ThrottledRequestReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,633] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,073] INFO Loading logs. (kafka.log.LogManager)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,876] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,081] INFO Logs loading complete in 8 ms. (kafka.log.LogManager)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,900] INFO [SocketServer brokerId=0] Started 1 acceptor threads (kafka.network.SocketServer)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,091] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,918] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,918] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,094] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,919] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,397] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,929] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,436] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[34;1mkafka3             |[0m [2018-04-27 08:52:51,945] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,454] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,126] INFO Result of znode creation at /brokers/ids/0 is: OK (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,128] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(kafka3,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,129] WARN No meta.properties file under dir /var/log/kafka/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,597] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,455] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,599] INFO Creating /controller (is it secure? false) (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,599] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,456] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,600] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,477] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,670] INFO Result of znode creation at /controller is: OK (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,676] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,677] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,681] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,496] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m [2018-04-27 08:52:52,981] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[34;1mkafka3             |[0m [2018-04-27 08:52:53,012] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[34;1mkafka3             |[0m [2018-04-27 08:52:53,014] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,746] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m [2018-04-27 08:52:53,014] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,748] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka2,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[34;1mkafka3             |[0m [2018-04-27 08:52:53,043] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[31;1mkafka2             |[0m [2018-04-27 08:52:50,750] WARN No meta.properties file under dir /var/log/kafka/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[34;1mkafka3             |[0m [2018-04-27 08:52:53,053] INFO Kafka version : 1.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka2             |[0m [2018-04-27 08:52:51,658] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:53,053] INFO Kafka commitId : fdcf75ea326b8e07 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka2             |[0m [2018-04-27 08:52:51,661] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[34;1mkafka3             |[0m [2018-04-27 08:52:53,054] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[31;1mkafka2             |[0m [2018-04-27 08:52:51,661] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[31;1mkafka2             |[0m [2018-04-27 08:52:51,662] INFO Creating /controller (is it secure? false) (kafka.zk.KafkaZkClient)
[31;1mkafka2             |[0m [2018-04-27 08:52:51,895] INFO Result of znode creation at /controller is: OK (kafka.zk.KafkaZkClient)
[31;1mkafka2             |[0m [2018-04-27 08:52:51,902] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[31;1mkafka2             |[0m [2018-04-27 08:52:51,903] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[31;1mkafka2             |[0m [2018-04-27 08:52:51,906] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[31;1mkafka2             |[0m [2018-04-27 08:52:52,215] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[31;1mkafka2             |[0m [2018-04-27 08:52:52,254] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[31;1mkafka2             |[0m [2018-04-27 08:52:52,256] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[31;1mkafka2             |[0m [2018-04-27 08:52:52,256] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[31;1mkafka2             |[0m [2018-04-27 08:52:52,297] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[31;1mkafka2             |[0m [2018-04-27 08:52:52,309] INFO Kafka version : 1.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka2             |[0m [2018-04-27 08:52:52,310] INFO Kafka commitId : fdcf75ea326b8e07 (org.apache.kafka.common.utils.AppInfoParser)
[31;1mkafka2             |[0m [2018-04-27 08:52:52,312] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[33;1mdatanode2          |[0m 2018-04-27 08:52:54,789 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[32mcheckpointnode exited with code 1
[0m[33;1mdatanode2          |[0m 2018-04-27 08:52:57,861 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:00,933 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:53:03,193 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51470
[36mzoo3               |[0m 2018-04-27 08:53:03,193 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:53:03,193 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51470 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:53:03,787 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51472
[33mzoo1               |[0m 2018-04-27 08:53:03,787 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:53:03,787 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51472 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:53:04,005 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35mzoo2               |[0m 2018-04-27 08:53:04,670 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51476
[35mzoo2               |[0m 2018-04-27 08:53:04,671 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:53:04,671 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51476 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:53:07,077 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:10,149 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:13,221 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:53:14,712] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:53:15,582] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:53:16,293 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:53:17,375] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:53:18,366 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[33;1mdatanode2          |[0m 2018-04-27 08:53:27,429 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:30,501 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:53:33,464 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51500
[36mzoo3               |[0m 2018-04-27 08:53:33,465 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:53:33,465 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51500 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:53:33,573 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33mzoo1               |[0m 2018-04-27 08:53:34,064 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51504
[33mzoo1               |[0m 2018-04-27 08:53:34,065 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:53:34,065 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51504 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:53:34,894 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51506
[35mzoo2               |[0m 2018-04-27 08:53:34,895 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:53:34,895 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51506 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:53:36,645 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:39,717 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:42,789 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:53:44,978] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:53:45,805] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:53:45,861 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:53:47,648] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:53:48,933 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:52,005 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:55,077 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:53:57,150 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[36mzoo3               |[0m 2018-04-27 08:54:03,710 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51534
[36mzoo3               |[0m 2018-04-27 08:54:03,710 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:54:03,710 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51534 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:54:04,301 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51536
[33mzoo1               |[0m 2018-04-27 08:54:04,301 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:54:04,301 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51536 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:54:05,117 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51538
[35mzoo2               |[0m 2018-04-27 08:54:05,117 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:54:05,117 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51538 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:54:06,213 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:09,285 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:12,357 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:54:15,216] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:54:15,429 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[31;1mkafka2             |[0m [2018-04-27 08:54:16,029] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[34;1mkafka3             |[0m [2018-04-27 08:54:17,895] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:54:18,501 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:21,573 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:24,645 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:27,717 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:30,789 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:33,861 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:54:34,012 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51580
[36mzoo3               |[0m 2018-04-27 08:54:34,013 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:54:34,013 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51580 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:54:34,516 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51582
[33mzoo1               |[0m 2018-04-27 08:54:34,517 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:54:34,517 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51582 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:54:35,342 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51584
[35mzoo2               |[0m 2018-04-27 08:54:35,342 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:54:35,342 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51584 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:54:35,934 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[33;1mdatanode2          |[0m 2018-04-27 08:54:44,997 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:54:45,469] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:54:46,251] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:54:48,069 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:54:48,139] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:54:51,141 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:54,214 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:54:57,285 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:00,357 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:03,429 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:55:04,246 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51610
[36mzoo3               |[0m 2018-04-27 08:55:04,246 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:55:04,246 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51610 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:55:04,739 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51612
[33mzoo1               |[0m 2018-04-27 08:55:04,740 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:55:04,740 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51612 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:55:05,563 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51614
[35mzoo2               |[0m 2018-04-27 08:55:05,563 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:55:05,563 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51614 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:55:06,501 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:09,573 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:12,645 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:14,717 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[35;1mkafka1             |[0m [2018-04-27 08:55:15,723] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:55:16,480] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[34;1mkafka3             |[0m [2018-04-27 08:55:18,402] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:55:23,781 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:26,854 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:29,925 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:32,997 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:55:34,537 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51640
[36mzoo3               |[0m 2018-04-27 08:55:34,538 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:55:34,538 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51640 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:55:34,989 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51642
[33mzoo1               |[0m 2018-04-27 08:55:34,990 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:55:34,990 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51642 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:55:35,787 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51644
[35mzoo2               |[0m 2018-04-27 08:55:35,788 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:55:35,788 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51644 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:55:36,069 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:39,141 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:42,213 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:45,285 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:55:45,954] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:55:46,794] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:55:48,357 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:55:48,669] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:55:51,429 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:55:53,501 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[33;1mdatanode2          |[0m 2018-04-27 08:56:02,565 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:56:04,748 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51682
[36mzoo3               |[0m 2018-04-27 08:56:04,748 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:56:04,748 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51682 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:56:05,218 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51684
[33mzoo1               |[0m 2018-04-27 08:56:05,219 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:56:05,219 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51684 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:56:05,637 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35mzoo2               |[0m 2018-04-27 08:56:06,009 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51688
[35mzoo2               |[0m 2018-04-27 08:56:06,009 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:56:06,009 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51688 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:56:08,709 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:11,781 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:14,853 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:56:16,203] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:56:17,027] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:56:17,925 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:56:18,920] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:56:20,997 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:24,069 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:27,141 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:30,213 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:32,285 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[36mzoo3               |[0m 2018-04-27 08:56:34,998 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51714
[36mzoo3               |[0m 2018-04-27 08:56:34,998 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:56:34,998 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51714 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:56:35,411 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51716
[33mzoo1               |[0m 2018-04-27 08:56:35,412 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:56:35,412 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51716 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:56:36,232 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51718
[35mzoo2               |[0m 2018-04-27 08:56:36,232 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:56:36,232 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51718 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:56:41,349 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:44,421 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:56:46,454] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:56:47,250] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:56:47,493 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:56:49,171] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:56:50,565 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:53,637 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:56,709 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:56:59,781 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:02,853 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:57:05,236 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51746
[36mzoo3               |[0m 2018-04-27 08:57:05,237 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:57:05,237 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51746 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:57:05,604 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51748
[33mzoo1               |[0m 2018-04-27 08:57:05,604 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:57:05,605 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51748 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:57:05,926 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35mzoo2               |[0m 2018-04-27 08:57:06,446 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51752
[35mzoo2               |[0m 2018-04-27 08:57:06,446 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:57:06,446 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51752 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:57:08,997 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:11,070 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[35;1mkafka1             |[0m [2018-04-27 08:57:16,706] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:57:17,487] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[34;1mkafka3             |[0m [2018-04-27 08:57:19,429] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:57:20,133 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:23,205 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:26,277 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:29,349 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:32,421 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:35,493 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:57:35,497 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51790
[36mzoo3               |[0m 2018-04-27 08:57:35,497 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:57:35,497 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51790 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:57:35,787 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51792
[33mzoo1               |[0m 2018-04-27 08:57:35,788 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:57:35,788 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51792 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:57:36,710 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51794
[35mzoo2               |[0m 2018-04-27 08:57:36,711 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:57:36,711 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51794 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:57:38,565 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:41,637 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:57:44,709 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:57:46,998] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:57:47,729] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:57:47,781 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:57:49,682] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:57:49,853 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[33;1mdatanode2          |[0m 2018-04-27 08:57:58,917 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:01,989 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:05,061 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:58:05,738 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51820
[36mzoo3               |[0m 2018-04-27 08:58:05,739 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:58:05,739 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51820 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:58:05,977 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51822
[33mzoo1               |[0m 2018-04-27 08:58:05,977 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:58:05,978 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51822 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:58:06,938 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51824
[35mzoo2               |[0m 2018-04-27 08:58:06,939 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:58:06,939 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51824 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:58:08,133 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:11,205 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:14,277 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:58:17,271] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:58:17,349 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[31;1mkafka2             |[0m [2018-04-27 08:58:17,956] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[34;1mkafka3             |[0m [2018-04-27 08:58:19,933] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:58:20,421 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:23,493 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:26,565 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:28,637 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[36mzoo3               |[0m 2018-04-27 08:58:35,989 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51850
[36mzoo3               |[0m 2018-04-27 08:58:35,989 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:58:35,989 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51850 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:58:36,165 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51852
[33mzoo1               |[0m 2018-04-27 08:58:36,165 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:58:36,165 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51852 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:58:37,166 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51854
[35mzoo2               |[0m 2018-04-27 08:58:37,166 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:58:37,166 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51854 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:58:37,701 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:40,773 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:43,845 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:46,917 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:58:47,543] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:58:48,190] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:58:49,989 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:58:50,187] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:58:53,061 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:56,133 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:58:59,205 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:02,277 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:05,349 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:59:06,240 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51886
[36mzoo3               |[0m 2018-04-27 08:59:06,240 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:59:06,241 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51886 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:59:06,351 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51888
[33mzoo1               |[0m 2018-04-27 08:59:06,351 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:59:06,351 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51888 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:59:07,389 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51902
[35mzoo2               |[0m 2018-04-27 08:59:07,390 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:59:07,390 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51902 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:59:07,425 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[33;1mdatanode2          |[0m 2018-04-27 08:59:16,485 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35;1mkafka1             |[0m [2018-04-27 08:59:17,809] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:59:18,415] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:59:19,557 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[34;1mkafka3             |[0m [2018-04-27 08:59:20,436] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:59:22,629 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:25,701 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:28,773 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:31,845 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:34,917 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 08:59:36,504 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51928
[36mzoo3               |[0m 2018-04-27 08:59:36,505 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 08:59:36,505 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51928 (no session established for client)
[33mzoo1               |[0m 2018-04-27 08:59:36,539 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51930
[33mzoo1               |[0m 2018-04-27 08:59:36,540 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 08:59:36,540 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51930 (no session established for client)
[35mzoo2               |[0m 2018-04-27 08:59:37,638 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51932
[35mzoo2               |[0m 2018-04-27 08:59:37,639 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 08:59:37,639 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51932 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 08:59:37,989 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:41,061 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:44,133 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:46,206 WARN datanode.DataNode: Problem connecting to server: namenode/172.28.0.2:9000
[35;1mkafka1             |[0m [2018-04-27 08:59:48,065] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[35;1mkafka1             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[35;1mkafka1             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[35;1mkafka1             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[35;1mkafka1             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[35;1mkafka1             |[0m 	at java.lang.Thread.run(Thread.java:748)
[31;1mkafka2             |[0m [2018-04-27 08:59:48,623] WARN [SocketServer brokerId=1] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[31;1mkafka2             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[31;1mkafka2             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[31;1mkafka2             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[31;1mkafka2             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[31;1mkafka2             |[0m 	at java.lang.Thread.run(Thread.java:748)
[34;1mkafka3             |[0m [2018-04-27 08:59:50,686] WARN [SocketServer brokerId=0] Unexpected error from /127.0.0.1; closing connection (org.apache.kafka.common.network.Selector)
[34;1mkafka3             |[0m org.apache.kafka.common.network.InvalidReceiveException: Invalid receive (size = 1195725856 larger than 104857600)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFromReadableChannel(NetworkReceive.java:132)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:93)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:235)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:196)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:557)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:495)
[34;1mkafka3             |[0m 	at org.apache.kafka.common.network.Selector.poll(Selector.java:424)
[34;1mkafka3             |[0m 	at kafka.network.Processor.poll(SocketServer.scala:628)
[34;1mkafka3             |[0m 	at kafka.network.Processor.run(SocketServer.scala:545)
[34;1mkafka3             |[0m 	at java.lang.Thread.run(Thread.java:748)
[33;1mdatanode2          |[0m 2018-04-27 08:59:55,269 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 08:59:58,341 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 09:00:01,413 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 09:00:04,485 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[36mzoo3               |[0m 2018-04-27 09:00:06,859 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51958
[36mzoo3               |[0m 2018-04-27 09:00:06,859 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[36mzoo3               |[0m 2018-04-27 09:00:06,859 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51958 (no session established for client)
[33mzoo1               |[0m 2018-04-27 09:00:06,878 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51960
[33mzoo1               |[0m 2018-04-27 09:00:06,878 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[33mzoo1               |[0m 2018-04-27 09:00:06,878 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51960 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 09:00:07,557 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[35mzoo2               |[0m 2018-04-27 09:00:07,871 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@192] - Accepted socket connection from /127.0.0.1:51964
[35mzoo2               |[0m 2018-04-27 09:00:07,872 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x0 due to java.io.IOException: Len error 1195725856
[35mzoo2               |[0m 2018-04-27 09:00:07,872 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1044] - Closed socket connection for client /127.0.0.1:51964 (no session established for client)
[33;1mdatanode2          |[0m 2018-04-27 09:00:10,629 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[33;1mdatanode2          |[0m 2018-04-27 09:00:13,702 INFO ipc.Client: Retrying connect to server: namenode/172.28.0.2:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
Gracefully stopping... (press Ctrl+C again to force)
